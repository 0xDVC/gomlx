/***** File generated by ./internal/cmd/simplego_generator, based on github.com/gomlx/gopjrt. Don't edit it directly. *****/

package simplego

import (
	"github.com/gomlx/exceptions"
	"github.com/gomlx/gomlx/backends"
	"github.com/gomlx/gomlx/types/shapes"
	"github.com/gomlx/gopjrt/dtypes"
	"github.com/gomlx/gopjrt/dtypes/bfloat16"
	"math"
)

func init() {
	nodeExecutors[backends.OpTypeAdd] = execAdd
	nodeExecutors[backends.OpTypeMul] = execMul
	nodeExecutors[backends.OpTypeSub] = execSub
	nodeExecutors[backends.OpTypeDiv] = execDiv
	nodeExecutors[backends.OpTypeRem] = execRem
	nodeExecutors[backends.OpTypePow] = execPow
	nodeExecutors[backends.OpTypeMax] = execMax
	nodeExecutors[backends.OpTypeMin] = execMin
	nodeExecutors[backends.OpTypeBitwiseAnd] = execBitwiseAnd
	nodeExecutors[backends.OpTypeBitwiseOr] = execBitwiseOr
	nodeExecutors[backends.OpTypeBitwiseXor] = execBitwiseXor
	nodeExecutors[backends.OpTypeLogicalAnd] = execLogicalAnd
	nodeExecutors[backends.OpTypeLogicalOr] = execLogicalOr
	nodeExecutors[backends.OpTypeLogicalXor] = execLogicalXor
}

// execAdd executes the binary op Add.
func execAdd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	// Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch output.shape.DType {
	case dtypes.Uint8:
		execAddNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execAddNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execAddNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execAddNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execAddNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execAddNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execAddNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execAddNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execAddNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execAddNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execAddNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execAddNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input + c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input + rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] + rhs[rhsIdx]
		}
	}
	return
}

func execAddNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a + c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a + b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a + b)
		}
	}
	return
}

// execMul executes the binary op Mul.
func execMul(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	// Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch output.shape.DType {
	case dtypes.Uint8:
		execMulNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execMulNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execMulNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execMulNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execMulNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execMulNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execMulNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execMulNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execMulNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execMulNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execMulNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execMulNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input * c
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input * rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] * rhs[rhsIdx]
		}
	}
	return
}

func execMulNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a * c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a * b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a * b)
		}
	}
	return
}

// execSub executes the binary op Sub.
func execSub(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execSubNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execSubNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execSubNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execSubNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execSubNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execSubNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execSubNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execSubNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execSubNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execSubNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execSubNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execSubNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input - c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c - input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input - rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] - rhs[rhsIdx]
		}
	}
	return
}

func execSubNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a - c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(c - a)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a - b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a - b)
		}
	}
	return
}

// execDiv executes the binary op Div.
func execDiv(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execDivNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execDivNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execDivNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execDivNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execDivNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execDivNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execDivNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execDivNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execDivNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execDivNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execDivNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execDivNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input / c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c / input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input / rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] / rhs[rhsIdx]
		}
	}
	return
}

func execDivNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(a / c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(c / a)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a / b)
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(a / b)
		}
	}
	return
}

// execRem executes the binary op Rem.
func execRem(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execRemIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execRemIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execRemIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execRemIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execRemIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execRemIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execRemIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execRemIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execRemFloatGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execRemFloatGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execRemFloatBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execRemIntegerGeneric[T podIntegerConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input % c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c % input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input % rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] % rhs[rhsIdx]
		}
	}
	return
}

func execRemFloatGeneric[T podFloatConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = T(math.Mod(float64(input), float64(c)))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = T(math.Mod(float64(c), float64(input)))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = T(math.Mod(float64(input), float64(rhs[ii])))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = T(math.Mod(float64(lhs[lhsIdx]), float64(rhs[rhsIdx])))
		}
	}
	return
}

func execRemFloatBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(c))))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Mod(float64(c), float64(a))))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(b))))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Mod(float64(a), float64(b))))
		}
	}
	return
}

// execPow executes the binary op Pow.
func execPow(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execPowIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execPowIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execPowIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execPowIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execPowIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execPowIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execPowIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execPowIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execPowFloatGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execPowFloatGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execPowFloatBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execPowIntegerGeneric[T podIntegerConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = execScalarPowIntGeneric(input, c)
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = execScalarPowIntGeneric(c, input)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = execScalarPowIntGeneric(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = execScalarPowIntGeneric(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execPowFloatGeneric[T podFloatConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = T(math.Pow(float64(input), float64(c)))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = T(math.Pow(float64(c), float64(input)))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = T(math.Pow(float64(input), float64(rhs[ii])))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = T(math.Pow(float64(lhs[lhsIdx]), float64(rhs[rhsIdx])))
		}
	}
	return
}

func execPowFloatBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(c))))
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0].Float32()
		for ii, input := range rhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(float32(math.Pow(float64(c), float64(a))))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(b))))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(float32(math.Pow(float64(a), float64(b))))
		}
	}
	return
}

// execMax executes the binary op Max.
func execMax(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	// Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch output.shape.DType {
	case dtypes.Uint8:
		execMaxNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execMaxNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execMaxNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execMaxNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execMaxNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execMaxNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execMaxNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execMaxNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execMaxNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execMaxNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execMaxNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execMaxNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = max(input, c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = max(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = max(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execMaxNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(max(a, c))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(max(a, b))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(max(a, b))
		}
	}
	return
}

// execMin executes the binary op Min.
func execMin(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	// Add is commutative, so if any of the two is scalar, make the rhs the scalar one.
	if lhsIsScalarOr1 && !rhsIsScalarOr1 {
		lhs, rhs = rhs, lhs
		lhsIsScalarOr1, rhsIsScalarOr1 = rhsIsScalarOr1, lhsIsScalarOr1
	}

	switch output.shape.DType {
	case dtypes.Uint8:
		execMinNumericGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execMinNumericGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execMinNumericGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execMinNumericGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execMinNumericGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execMinNumericGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execMinNumericGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execMinNumericGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float32:
		execMinNumericGeneric[float32](lhs.flat.([]float32), rhs.flat.([]float32), output.flat.([]float32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Float64:
		execMinNumericGeneric[float64](lhs.flat.([]float64), rhs.flat.([]float64), output.flat.([]float64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.BFloat16:
		execMinNumericBFloat16(lhs.flat.([]bfloat16.BFloat16), rhs.flat.([]bfloat16.BFloat16), output.flat.([]bfloat16.BFloat16),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execMinNumericGeneric[T podNumericConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = min(input, c)
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = min(input, rhs[ii])
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = min(lhs[lhsIdx], rhs[rhsIdx])
		}
	}
	return
}

func execMinNumericBFloat16(lhs, rhs, output []bfloat16.BFloat16,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0].Float32()
		for ii, input := range lhs {
			a := input.Float32()
			output[ii] = bfloat16.FromFloat32(min(a, c))
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for outputIdx := range output {
			a := lhs[outputIdx].Float32()
			b := rhs[outputIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(min(a, b))
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			a := lhs[lhsIdx].Float32()
			b := rhs[rhsIdx].Float32()
			output[outputIdx] = bfloat16.FromFloat32(min(a, b))
		}
	}
	return
}

// execBitwiseAnd executes the binary op BitwiseAnd.
func execBitwiseAnd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execBitwiseAndIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execBitwiseAndIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execBitwiseAndIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execBitwiseAndIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execBitwiseAndIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execBitwiseAndIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execBitwiseAndIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execBitwiseAndIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execBitwiseAndIntegerGeneric[T podIntegerConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input & c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c & input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input & rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] & rhs[rhsIdx]
		}
	}
	return
}

// execBitwiseOr executes the binary op BitwiseOr.
func execBitwiseOr(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execBitwiseOrIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execBitwiseOrIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execBitwiseOrIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execBitwiseOrIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execBitwiseOrIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execBitwiseOrIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execBitwiseOrIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execBitwiseOrIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execBitwiseOrIntegerGeneric[T podIntegerConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input | c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c | input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input | rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] | rhs[rhsIdx]
		}
	}
	return
}

// execBitwiseXor executes the binary op BitwiseXor.
func execBitwiseXor(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	case dtypes.Uint8:
		execBitwiseXorIntegerGeneric[uint8](lhs.flat.([]uint8), rhs.flat.([]uint8), output.flat.([]uint8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint16:
		execBitwiseXorIntegerGeneric[uint16](lhs.flat.([]uint16), rhs.flat.([]uint16), output.flat.([]uint16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint32:
		execBitwiseXorIntegerGeneric[uint32](lhs.flat.([]uint32), rhs.flat.([]uint32), output.flat.([]uint32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Uint64:
		execBitwiseXorIntegerGeneric[uint64](lhs.flat.([]uint64), rhs.flat.([]uint64), output.flat.([]uint64),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int8:
		execBitwiseXorIntegerGeneric[int8](lhs.flat.([]int8), rhs.flat.([]int8), output.flat.([]int8),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int16:
		execBitwiseXorIntegerGeneric[int16](lhs.flat.([]int16), rhs.flat.([]int16), output.flat.([]int16),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int32:
		execBitwiseXorIntegerGeneric[int32](lhs.flat.([]int32), rhs.flat.([]int32), output.flat.([]int32),
			lhs.shape, rhs.shape, output.shape)
	case dtypes.Int64:
		execBitwiseXorIntegerGeneric[int64](lhs.flat.([]int64), rhs.flat.([]int64), output.flat.([]int64),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execBitwiseXorIntegerGeneric[T podIntegerConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input ^ c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c ^ input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input ^ rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] ^ rhs[rhsIdx]
		}
	}
	return
}

// execLogicalAnd executes the binary op LogicalAnd.
func execLogicalAnd(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalAndBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execLogicalAndBooleanGeneric[T podBooleanConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input && c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c && input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input && rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] && rhs[rhsIdx]
		}
	}
	return
}

// execLogicalOr executes the binary op LogicalOr.
func execLogicalOr(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalOrBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execLogicalOrBooleanGeneric[T podBooleanConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input || c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c || input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input || rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] || rhs[rhsIdx]
		}
	}
	return
}

// execLogicalXor executes the binary op LogicalXor.
func execLogicalXor(backend *Backend, node *Node, inputs []*Buffer, inputsOwned []bool) *Buffer {
	lhs, rhs, output, lhsIsScalarOr1, rhsIsScalarOr1 := binaryOperandsAndOutput(backend, inputs, inputsOwned, node.shape)

	_, _ = lhsIsScalarOr1, rhsIsScalarOr1

	switch output.shape.DType {
	// Boolean:
	case dtypes.Bool:
		execLogicalXorBooleanGeneric[bool](lhs.flat.([]bool), rhs.flat.([]bool), output.flat.([]bool),
			lhs.shape, rhs.shape, output.shape)
	default:
		exceptions.Panicf("unsupported data type %s for %s", output.shape.DType, node.opType)
	}
	return output
}

func execLogicalXorBooleanGeneric[T podBooleanConstraints](lhs, rhs, output []T,
	lhsShape, rhsShape, outputShape shapes.Shape) {
	if len(rhs) == 1 {
		// Case 1: One side (rhs) is a scalar: only iterate over the lhs.
		c := rhs[0]
		for ii, input := range lhs {
			output[ii] = input != c
		}
		return
	} else if len(lhs) == 1 {
		// Case 1b: One side (lhs) is a scalar: only iterate over the rhs.
		c := lhs[0]
		for ii, input := range rhs {
			output[ii] = c != input
		}
		return

	} else if lhsShape.Equal(rhsShape) {
		// Case 2: Exact same shapes, no broadcasting.
		for ii, input := range lhs {
			output[ii] = input != rhs[ii]
		}
		return

	} else {
		// Case 3: with broadcasting non-scalar tensors:
		lhsIter := newBroadcastIterator(lhsShape, outputShape)
		rhsIter := newBroadcastIterator(rhsShape, outputShape)
		for outputIdx := range output {
			lhsIdx := lhsIter.Next()
			rhsIdx := rhsIter.Next()
			output[outputIdx] = lhs[lhsIdx] != rhs[rhsIdx]
		}
	}
	return
}
