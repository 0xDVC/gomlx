{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "546fa208-c19c-405b-81b1-cf99fcb4a830",
   "metadata": {
    "tags": []
   },
   "source": [
    "# UCI Adult Dataset or Census Income\n",
    "\n",
    "This is a very popular ML task, with tabular data. The objective is to predict whether income exceeds $50K/yr based on census data. \n",
    "Also known as \"Census Income\" dataset.\n",
    "\n",
    "The data is old and biased on different ways ... but it can be used opaquely for ML experimentation.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ab071e3-227f-4c77-b864-2b7e5a5ccbdf",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9ba46cb6-059d-4387-876c-665f778f2447",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "!*go mod edit -replace github.com/gomlx/gomlx=\"${HOME}/Projects/gomlx\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78cf991f-4fa5-4bae-8e49-ca67fb8dbd5b",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "GoMLX provides [a simple `adult` library](https://pkg.go.dev/github.com/gomlx/gomlx/examples/adult) to facilitate downdoaling and preprocessing the data. Data is available in [UCI Machine Learning Repository](https://archive.ics.uci.edu/ml/datasets/Adult).\n",
    "\n",
    "After downloading the data and validating the checksum (both training and testing), it generates the quantiles for the continuous features, and the vocabularies for the categorical features. It saves all this info for faster restart later in a binary file. So this won't be necessary a second time.\n",
    "\n",
    "The quantiles are used to calibrate the values, using a piece-wise-lienar calibration, very good for these things. See [`layers.PieceWiseLinearCalibration` documentation](https://pkg.go.dev/github.com/gomlx/gomlx@v0.1.0/ml/layers#PieceWiseLinearCalibration).\n",
    "\n",
    "We create a flag `--data` to define the directory where to save the intermediary files: downloaded and preprocessed datasets.\n",
    "In this examle we set it to `~/work/uci-adult`. Verbosity can be contolled with the `--verbosity` flag. \n",
    "\n",
    "We set default in Go for these flags, but they can easily be reset for a new run by providing them after the `%%` Jupyter kernel meta-command -- in indicates that the subsequent lines should be put in to a `func main`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9418be86-70bc-41ad-9e0a-3a5e6bf52b51",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading datasets:\n",
      "Downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data ...\n",
      "/ -1 B  [1s] \n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.data => /home/jupyter/work/uci-adult/adult.data\n",
      "Downloading https://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test ...\n",
      "- -1 B  [0s] \n",
      "\thttps://archive.ics.uci.edu/ml/machine-learning-databases/adult/adult.test => /home/jupyter/work/uci-adult/adult.test\n",
      "[32561x15] DataFrame\n",
      "\n",
      "    age       workclass        fnlwgt        education education-num ...\n",
      " 0: 39.000000 State-gov        77516.000000  Bachelors 13.000000     ...\n",
      " 1: 50.000000 Self-emp-not-inc 83311.000000  Bachelors 13.000000     ...\n",
      " 2: 38.000000 Private          215646.000000 HS-grad   9.000000      ...\n",
      " 3: 53.000000 Private          234721.000000 11th      7.000000      ...\n",
      " 4: 28.000000 Private          338409.000000 Bachelors 13.000000     ...\n",
      " 5: 37.000000 Private          284582.000000 Masters   14.000000     ...\n",
      " 6: 49.000000 Private          160187.000000 9th       5.000000      ...\n",
      " 7: 52.000000 Self-emp-not-inc 209642.000000 HS-grad   9.000000      ...\n",
      " 8: 31.000000 Private          45781.000000  Masters   14.000000     ...\n",
      " 9: 42.000000 Private          159449.000000 Bachelors 13.000000     ...\n",
      "    ...       ...              ...           ...       ...           ...\n",
      "    <float>   <string>         <float>       <string>  <float>       ...\n",
      "\n",
      "Not Showing: marital-status <string>, occupation <string>, relationship <string>,\n",
      "race <string>, sex <string>, capital-gain <float>, capital-loss <float>,\n",
      "hours-per-week <float>, native-country <string>, label <string>\n",
      "\n",
      "Vocabularies:\n",
      "\tFeature \"workclass\":\n",
      "\t\t\"Federal-gov\":1\n",
      "\t\t\"Self-emp-inc\":5\n",
      "\t\t\"Never-worked\":3\n",
      "\t\t\"?\":0\n",
      "\t\t\"State-gov\":7\n",
      "\t\t\"Self-emp-not-inc\":6\n",
      "\t\t\"Private\":4\n",
      "\t\t\"Local-gov\":2\n",
      "\t\t\"Without-pay\":8\n",
      "\tFeature \"education\":\n",
      "\t\t\"Doctorate\":11\n",
      "\t\t\"1st-4th\":4\n",
      "\t\t\"11th\":2\n",
      "\t\t\"7th-8th\":6\n",
      "\t\t\"Prof-school\":15\n",
      "\t\t\"5th-6th\":5\n",
      "\t\t\"Preschool\":14\n",
      "\t\t\"12th\":3\n",
      "\t\t\"Bachelors\":10\n",
      "\t\t\"9th\":7\n",
      "\t\t\"Assoc-acdm\":8\n",
      "\t\t\"Some-college\":16\n",
      "\t\t\"Assoc-voc\":9\n",
      "\t\t\"10th\":1\n",
      "\t\t\"?\":0\n",
      "\t\t\"HS-grad\":12\n",
      "\t\t\"Masters\":13\n",
      "\tFeature \"marital-status\":\n",
      "\t\t\"?\":0\n",
      "\t\t\"Never-married\":5\n",
      "\t\t\"Married-civ-spouse\":3\n",
      "\t\t\"Divorced\":1\n",
      "\t\t\"Married-spouse-absent\":4\n",
      "\t\t\"Separated\":6\n",
      "\t\t\"Married-AF-spouse\":2\n",
      "\t\t\"Widowed\":7\n",
      "\tFeature \"occupation\":\n",
      "\t\t\"Adm-clerical\":1\n",
      "\t\t\"Sales\":12\n",
      "\t\t\"Craft-repair\":3\n",
      "\t\t\"Machine-op-inspct\":7\n",
      "\t\t\"Protective-serv\":11\n",
      "\t\t\"Other-service\":8\n",
      "\t\t\"Farming-fishing\":5\n",
      "\t\t\"Tech-support\":13\n",
      "\t\t\"?\":0\n",
      "\t\t\"Transport-moving\":14\n",
      "\t\t\"Armed-Forces\":2\n",
      "\t\t\"Exec-managerial\":4\n",
      "\t\t\"Handlers-cleaners\":6\n",
      "\t\t\"Prof-specialty\":10\n",
      "\t\t\"Priv-house-serv\":9\n",
      "\tFeature \"relationship\":\n",
      "\t\t\"?\":0\n",
      "\t\t\"Not-in-family\":2\n",
      "\t\t\"Husband\":1\n",
      "\t\t\"Wife\":6\n",
      "\t\t\"Own-child\":4\n",
      "\t\t\"Unmarried\":5\n",
      "\t\t\"Other-relative\":3\n",
      "\tFeature \"race\":\n",
      "\t\t\"Amer-Indian-Eskimo\":1\n",
      "\t\t\"Other\":4\n",
      "\t\t\"?\":0\n",
      "\t\t\"White\":5\n",
      "\t\t\"Black\":3\n",
      "\t\t\"Asian-Pac-Islander\":2\n",
      "\tFeature \"sex\":\n",
      "\t\t\"Male\":2\n",
      "\t\t\"Female\":1\n",
      "\t\t\"?\":0\n",
      "\tFeature \"native-country\":\n",
      "\t\t\"United-States\":39\n",
      "\t\t\"Jamaica\":23\n",
      "\t\t\"Mexico\":26\n",
      "\t\t\"Honduras\":16\n",
      "\t\t\"Canada\":2\n",
      "\t\t\"Iran\":20\n",
      "\t\t\"Philippines\":30\n",
      "\t\t\"South\":35\n",
      "\t\t\"Germany\":11\n",
      "\t\t\"Columbia\":4\n",
      "\t\t\"Taiwan\":36\n",
      "\t\t\"France\":10\n",
      "\t\t\"Japan\":24\n",
      "\t\t\"Yugoslavia\":41\n",
      "\t\t\"Greece\":12\n",
      "\t\t\"Nicaragua\":27\n",
      "\t\t\"?\":0\n",
      "\t\t\"Poland\":31\n",
      "\t\t\"Haiti\":14\n",
      "\t\t\"El-Salvador\":8\n",
      "\t\t\"Guatemala\":13\n",
      "\t\t\"Trinadad&Tobago\":38\n",
      "\t\t\"Cuba\":5\n",
      "\t\t\"India\":19\n",
      "\t\t\"Cambodia\":1\n",
      "\t\t\"Outlying-US(Guam-USVI-etc)\":28\n",
      "\t\t\"Vietnam\":40\n",
      "\t\t\"Hungary\":18\n",
      "\t\t\"Italy\":22\n",
      "\t\t\"Thailand\":37\n",
      "\t\t\"Portugal\":32\n",
      "\t\t\"Dominican-Republic\":6\n",
      "\t\t\"China\":3\n",
      "\t\t\"Ecuador\":7\n",
      "\t\t\"Scotland\":34\n",
      "\t\t\"Puerto-Rico\":33\n",
      "\t\t\"England\":9\n",
      "\t\t\"Peru\":29\n",
      "\t\t\"Ireland\":21\n",
      "\t\t\"Laos\":25\n",
      "\t\t\"Hong\":17\n",
      "\t\t\"Holand-Netherlands\":15\n",
      "\n",
      "Quantiles:\n",
      "\tFeature \"age\", 52 quantiles:\n",
      "\t\t[17 18 19 20 21 22 23 24 25 26 27 28 29 30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53 54 55 56 57 58 59 60 61 62 63 65 67 69 74 90]\n",
      "\tFeature \"education-num\", 15 quantiles:\n",
      "\t\t[1 3 4 5 6 7 8 9 10 11 12 13 14 15 16]\n",
      "\tFeature \"capital-gain\", 51 quantiles:\n",
      "\t\t[0 594 991 1086 1471 1797 2105 2174 2202 2329 2407 2463 2597 2829 2907 2977 3103 3137 3325 3411 3464 3674 3887 3908 4064 4101 4386 4416 4650 4687 4865 5013 5178 5455 6418 6849 7298 7430 7688 8614 9386 10520 10605 13550 14084 14344 15024 20051 27828 34095 99999]\n",
      "\tFeature \"capital-loss\", 47 quantiles:\n",
      "\t\t[0 625 880 1258 1380 1408 1485 1504 1564 1573 1579 1590 1602 1617 1628 1668 1669 1672 1719 1721 1740 1741 1762 1848 1876 1887 1902 1974 1977 1980 2001 2002 2042 2051 2057 2174 2201 2206 2258 2339 2377 2415 2444 2467 2559 2824 4356]\n",
      "\tFeature \"hours-per-week\", 29 quantiles:\n",
      "\t\t[1 8 10 15 18 20 22 25 26 30 32 35 36 37 38 40 42 43 45 48 50 52 55 57 60 65 70 80 99]\n",
      "\n",
      "Sample Categorical: (24.08% positive ratio, 23.86% weighted positive ratio)\n",
      "\tRow 0:\t[7 10 5 1 2 5 2 39]\n",
      "\tRow 1:\t[6 10 3 4 1 5 2 39]\n",
      "\tRow 2:\t[4 12 1 6 2 5 2 39]\n",
      "\t...\n",
      "\tRow 32558:\t[4 12 7 1 5 5 1 39]\n",
      "\tRow 32559:\t[4 12 5 1 4 5 2 39]\n",
      "\tRow 32560:\t[5 12 3 4 6 5 1 39]\n",
      "\n",
      "Sample Continuous:\n",
      "\tRow 0:\t[39 13 2174 0 40]\n",
      "\tRow 1:\t[50 13 0 0 13]\n",
      "\tRow 2:\t[38 9 0 0 40]\n",
      "\t...\n",
      "\tRow 32558:\t[58 9 0 0 40]\n",
      "\tRow 32559:\t[22 9 0 0 20]\n",
      "\tRow 32560:\t[52 9 15024 0 40]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flag\"\n",
    "    \n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    flagDataDir       = flag.String(\"data\", \"~/work/uci-adult\", \"Directory to save and load downloaded and generated dataset files.\")\n",
    "    flagVerbosity     = flag.Int(\"verbosity\", 0, \"Level of verbosity, the higher the more verbose.\")\n",
    "    flagForceDownload = flag.Bool(\"force_download\", false, \"Force re-download of Adult dataset files.\")\n",
    "    flagNumQuantiles  = flag.Int(\"quantiles\", 100, \"Max number of quantiles to use for numeric features, used during piece-wise linear calibration. It will only use unique values, so if there are fewer variability, fewer quantiles are used.\")\n",
    ")\n",
    "\n",
    "%% --verbosity=2\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdab7255-2224-496a-9ec7-75927150f9d7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 7.0M\n",
      "-rw-r--r-- 1 jupyter users 3.8M Oct 26 03:45 adult.data\n",
      "-rw-r--r-- 1 jupyter users 2.0M Oct 26 03:45 adult.test\n",
      "-rw-r--r-- 1 jupyter users 1.3M Oct 26 03:45 adult_data-100_quantiles.bin\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/work/uci-adult"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "028b783b-56f0-457c-b28e-7bb0dd7e94da",
   "metadata": {},
   "source": [
    "### Creating Datasets\n",
    "\n",
    "First we create the GoMLX's `Manager`: it's the object that manages the underlying XLA\n",
    "setup, connection and execution. It's needed to create tensors.\n",
    "\n",
    "With that we create the samplers of data that we will use to train and evaluate. They implement \n",
    "GoMLX's `train.Dataset` interface, which is what is used by our training loop to draw batches to\n",
    "train, or our eval loop to draw batches to evaluate.\n",
    "\n",
    "The inputs are 3 tensors: *categorical values*, *continuous values* and *weights*.\n",
    "\n",
    "In the cell below we define the `Manager` flags, `BuildSamplers` and printout some samples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f13f771b-7109-49d2-8db5-5f3d5a91d324",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inputs of batch (size 128):\n",
      "\tcategorical:\n",
      "\t\tFeatures=[workclass education marital-status occupation relationship race sex native-country]\n",
      "\t\tValues: (Int64)[128 8]: (... too large, 1024 values ..., first 16 values: [6 12 3 5 1 5 2 39 1 12 3 4 1 5 2 39])\n",
      "\tcontinuous:\n",
      "\t\tFeatures=[age education-num capital-gain capital-loss hours-per-week]\n",
      "\t\tValues: (Float32)[128 5]: (... too large, 640 values ..., first 10 values: [79 9 0 0 40 40 9 0 0 40])\n",
      "\tweights: (Float32)[128 1]: (... too large, 128 values ..., first 5 values: [103684 219266 119904 48014 125461])\n",
      "\n",
      "Labels of batch:\n",
      "\t(Float32)[128 1]: (... too large, 128 values ..., first 10 values: [0 1 1 0 1 0 0 1 1 1])\n",
      "\n",
      "Labels distributions:\n",
      "\tTrain:\t24.08% positive\n",
      "\tTest:\t23.62% positive\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flag\"\n",
    "    \"fmt\"\n",
    "    \"io\"\n",
    "\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    "    \"github.com/gomlx/gomlx/ml/train\"\n",
    "    \"github.com/gomlx/gomlx/types/tensor\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    flagBatchSize      = flag.Int(\"batch\", 128, \"BatchSampler size for training\")\n",
    ")\n",
    "\n",
    "// Global manager created an initialization, used everywhere.\n",
    "var manager = NewManager()\n",
    "\n",
    "// BuildDatasets returns 3 `train.Dataset`:\n",
    "// * trainingSampler is an endless random sampler used for training.\n",
    "// * trainingEvalSampler samples through exactly one epoch of the train dataset.\n",
    "// * testEvalSampler samples through exactly one epoch of the test dataset.\n",
    "func BuildDatasets(manager *Manager) (trainDS, trainEvalDS, testEvalDS train.Dataset) {\n",
    "    baseDS := adult.NewDataset(manager, adult.Data.Train, \"batched train\")\n",
    "    trainEvalDS = baseDS.Copy().BatchSize(*flagBatchSize, false)\n",
    "    testEvalDS = adult.NewDataset(manager, adult.Data.Test, \"test\").\n",
    "        BatchSize(*flagBatchSize, false)\n",
    "    // For training, we shuffle and loop indefinitely.\n",
    "    trainDS = baseDS.BatchSize(*flagBatchSize, true).Shuffle().Infinite(true)\n",
    "    return\n",
    "}\n",
    "\n",
    "// PositiveRatio finds out the the ratio of positive labels in the\n",
    "// training and testing data.\n",
    "//\n",
    "// We could do this easily with GoMLX computation model (just `ReduceAllSum`), but\n",
    "// this examples shows it's also ok to mix Go computations.\n",
    "func PositiveRatio(ds train.Dataset) float32 {\n",
    "    ds.Reset()  // Start from beginning.\n",
    "    var sum float32\n",
    "    var count float32\n",
    "    for {\n",
    "        _, _, labels, err := ds.Yield()\n",
    "        if err == io.EOF {\n",
    "            break;\n",
    "        }\n",
    "        if err != nil { panic(err) }\n",
    "        data := labels[0].Local().Flat().([]float32)\n",
    "        for _, value := range data {\n",
    "            sum += value\n",
    "        }\n",
    "        count += float32(len(data))\n",
    "    }\n",
    "    return sum/count\n",
    "}\n",
    "\n",
    "%%\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "trainingDS, trainingEvalDS, testEvalDS := BuildDatasets(manager)\n",
    "\n",
    "// Take one batch.\n",
    "_, inputs, labels, err := trainingDS.Yield()\n",
    "if err != nil { panic(err) }\n",
    "fmt.Printf(\"Inputs of batch (size %d):\\n\", *flagBatchSize)\n",
    "fmt.Printf(\"\\tcategorical:\\n\\t\\tFeatures=%v\\n\", adult.Data.VocabulariesFeatures)\n",
    "fmt.Printf(\"\\t\\tValues: %s\\n\", inputs[0].Local().StringN(16))\n",
    "fmt.Printf(\"\\tcontinuous:\\n\\t\\tFeatures=%v\\n\", adult.Data.QuantilesFeatures)\n",
    "fmt.Printf(\"\\t\\tValues: %s\\n\", inputs[1].Local().StringN(10))\n",
    "fmt.Printf(\"\\tweights: %s\\n\", inputs[2].Local().StringN(5))\n",
    "fmt.Printf(\"\\nLabels of batch:\\n\\t%s\\n\", labels[0].Local().StringN(10))\n",
    "fmt.Printf(\"\\nLabels distributions:\\n\\tTrain:\\t%.2f%% positive\\n\\tTest:\\t%.2f%% positive\\n\",\n",
    "           PositiveRatio(trainingEvalDS)*100.0, PositiveRatio(testEvalDS)*100.0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54efd046-bbd5-4f7d-94e0-9ed3c64512b1",
   "metadata": {},
   "source": [
    "## Model Definition\n",
    "\n",
    "Lots of hyper-parameter flags, but otherwise a straight forward FNN, using piece-wise linear calibration of the continuous features, and embeddings for the categorical features.\n",
    "\n",
    "> **Note**: building models is a constant checking that shapes are compatible. It's a bit annoying, in particular because shapes are known in runtime only -- no compile time check. GoMLX tries to help providing a stack trace of where errors happen so one can pin-point issues quickly. But often it involves lots of experimentation (more than ordinary Go code).\n",
    ">\n",
    "> Developing with a Noteboook (see [GoNB](https://github.com/janpfeifer/gonb)) or simply a unit test on your `ModelGraph` function are quick/convenient ways to develop models -- before actually training them. You can also use shape asserts in the middle of the \n",
    ">`ModelGraph`, as we do below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7040e63b-33f1-4ff9-a232-187196c5f9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=128: (Float32)[128 1]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"io\"\n",
    "\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\n",
    "    \"github.com/gomlx/gomlx/ml/context\"\n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    "    \"github.com/gomlx/gomlx/ml/train\"\n",
    "    \"github.com/gomlx/gomlx/ml/train/optimizers\"\n",
    "    \"github.com/gomlx/gomlx/types/shapes\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    // ModelDType used for the model. Must match RawData Go types.\n",
    "    ModelDType = shapes.Float32\n",
    "    \n",
    "\n",
    "    // Model hyperparameters.\n",
    "    flagUseCategorical       = flag.Bool(\"use_categorical\", true, \"Use categorical features.\")\n",
    "    flagUseContinuous        = flag.Bool(\"use_continuous\", true, \"Use continuous features.\")\n",
    "    flagTrainableCalibration = flag.Bool(\"trainable_calibration\", true, \"Allow piece-wise linear calibration to adjust outputs.\")\n",
    "    flagEmbeddingDim    = flag.Int(\"embedding_dim\", 8, \"Default embedding dimension for categorical values.\")\n",
    "    flagNumHiddenLayers = flag.Int(\"hidden_layers\", 8, \"Number of hidden layers, stacked with residual connection.\")\n",
    "    flagNumNodes        = flag.Int(\"num_nodes\", 32, \"Number of nodes in hidden layers.\")\n",
    "    flagDropoutRate     = flag.Float64(\"dropout\", 0, \"Dropout rate\")\n",
    "    \n",
    "    // Training parameter, referenced here.\n",
    "    flagLearningRate  = flag.Float64(\"learning_rate\", 0.001, \"Initial learning rate.\")\n",
    "    flagNumSteps      = flag.Int(\"steps\", 5000, \"Number of gradient descent steps to perform\")\n",
    ")\n",
    "\n",
    "\n",
    "// ModelGraph outputs the logits (not the probabilities). The parameter inputs should contain 3 tensors:\n",
    "//\n",
    "// - categorical inputs, shaped  `(int64)[batch_size, len(VocabulariesFeatures)]`\n",
    "// - continuous inputs, shaped `(float32)[batch_size, len(Quantiles)]`\n",
    "// - weights: not currently used, but shaped `(float32)[batch_size, 1]`.\n",
    "func ModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "    _ = spec // Not used, since the dataset is always the same.\n",
    "    g := inputs[0].Graph()\n",
    "    \n",
    "    // Use Cosine schedule of the learning rate.\n",
    "    optimizers.CosineAnnealingSchedule(ctx, g, ModelDType).\n",
    "        PeriodInSteps(*flagNumSteps/3).Done()\n",
    "    \n",
    "    categorical, continuous := inputs[0], inputs[1]\n",
    "    batchSize := categorical.Shape().Dimensions[0]\n",
    "    \n",
    "    var allEmbeddings []*Node\n",
    "\n",
    "    if *flagUseCategorical {\n",
    "        // Embedding of categorical values, each with its own vocabulary.\n",
    "        numCategorical := categorical.Shape().Dimensions[1]\n",
    "        for catIdx := 0; catIdx < numCategorical; catIdx++ {\n",
    "            // Take one column at a time of the categorical values.\n",
    "            split := Slice(categorical, AxisRange(), AxisRange(catIdx, catIdx+1))\n",
    "            // Embed it accordingly.\n",
    "            embedCtx := ctx.In(fmt.Sprintf(\"categorical_%d_%s\", catIdx, adult.Data.VocabulariesFeatures[catIdx]))\n",
    "            vocab := adult.Data.Vocabularies[catIdx]\n",
    "            vocabSize := len(vocab)\n",
    "            embedding := layers.Embedding(embedCtx, split, ModelDType, vocabSize, *flagEmbeddingDim)\n",
    "            embedding.AssertDims(batchSize, *flagEmbeddingDim) // 2-dim tensor, with batch size as the leading dimension.\n",
    "            allEmbeddings = append(allEmbeddings, embedding)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    if *flagUseContinuous {\n",
    "        // Piecewise-linear calibration of the continuous values. Each feature has its own number of quantiles.\n",
    "        numContinuous := continuous.Shape().Dimensions[1]\n",
    "        for contIdx := 0; contIdx < numContinuous; contIdx++ {\n",
    "            // Take one column at a time of the continuous values.\n",
    "            split := Slice(continuous, AxisRange(), AxisRange(contIdx, contIdx+1))\n",
    "            featureName := adult.Data.QuantilesFeatures[contIdx]\n",
    "            calibrationCtx := ctx.In(fmt.Sprintf(\"continuous_%d_%s\", contIdx, featureName))\n",
    "            quantiles := adult.Data.Quantiles[contIdx]\n",
    "            layers.AssertQuantilesForPWLCalibrationValid(quantiles)\n",
    "            calibrated := layers.PieceWiseLinearCalibration(calibrationCtx, split, Const(g, quantiles), *flagTrainableCalibration)\n",
    "            calibrated.AssertDims(batchSize, 1) // 2-dim tensor, with batch size as the leading dimension.\n",
    "            allEmbeddings = append(allEmbeddings, calibrated)\n",
    "        }\n",
    "    }\n",
    "    layer := Concatenate(allEmbeddings, -1)\n",
    "    layer.AssertDims(batchSize, -1) // 2-dim tensor, with batch size as the leading dimension (-1 means it is not checked).\n",
    "    \n",
    "    layer = layers.DenseWithBias(ctx.In(fmt.Sprintf(\"DenseLayer_%d\", 0)), layer, *flagNumNodes)\n",
    "    for ii := 1; ii < *flagNumHiddenLayers; ii++ {\n",
    "        ctx := ctx.In(fmt.Sprintf(\"DenseLayer_%d\", ii))\n",
    "        // Add layer with residual connection.\n",
    "        tmp := Sigmoid(layer)\n",
    "        if *flagDropoutRate > 0 {\n",
    "            tmp = layers.Dropout(ctx, tmp, Scalar(g, ModelDType, *flagDropoutRate))\n",
    "        }\n",
    "        tmp = layers.DenseWithBias(ctx, tmp, *flagNumNodes)\n",
    "        layer = Add(layer, tmp)  // Residual connections\n",
    "    }\n",
    "    layer = Sigmoid(layer)\n",
    "    logits := layers.DenseWithBias(ctx.In(\"DenseFinal\"), layer, 1)\n",
    "    logits.AssertDims(batchSize, 1) // 2-dim tensor, with batch size as the leading dimension.\n",
    "    return []*Node{logits}\n",
    "}\n",
    "\n",
    "%%\n",
    "adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "\n",
    "// Let's just check that we get the right shape from the model function, wihtout any real data.\n",
    "graph := manager.NewGraph(\"test\")\n",
    "ctx := context.NewContext(manager)\n",
    "ctx.SetParam(optimizers.LearningRateKey, *flagLearningRate)\n",
    "\n",
    "// Create placeholder (parameters) graph nodes, just to test the graph building is working.\n",
    "inputs := []*Node{\n",
    "    // Categorical: shaped [batch_size, num_categorical]\n",
    "    graph.Parameter(\"categorical\", shapes.Make(shapes.Int64, *flagBatchSize, len(adult.Data.VocabulariesFeatures))),\n",
    "    // Continuous: shaped [batch_size, num_continuos]\n",
    "    graph.Parameter(\"continuous\", shapes.Make(shapes.Float32, *flagBatchSize, len(adult.Data.QuantilesFeatures))),\n",
    "    // Weights: shaped [batch_size, 1]\n",
    "    graph.Parameter(\"weights\", shapes.Make(shapes.Float32, *flagBatchSize, 1)),    \n",
    "}\n",
    "logits := ModelGraph(ctx, nil, inputs)\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", *flagBatchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "618e1c7a-ced1-4914-8530-0924e02f095c",
   "metadata": {},
   "source": [
    "## Training Loop\n",
    "\n",
    "We can create a training loop with only a `Manager`, a `Context` (for the model varibles) and the `ModelGraph` function.\n",
    "\n",
    "To make it more interesting we also add the following:\n",
    "\n",
    "* Accuracy metrics for training and testing.\n",
    "* Checkpoints -- so trained model can be saved, and reloaded.\n",
    "* A progress-bar that also shows training metrics.\n",
    "* We dynamically plot how the loss and accuracy evolve.\n",
    "\n",
    "First we define the corresponding flags and the `trainModel` function, and run it for very few steps to make sure\n",
    "it is working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "daf39a7c-7cc8-43a5-ae79-026303f5f502",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (500 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (221 steps/s)\u001b[0m [loss=0.333] [~loss=0.354] [~acc=84.10%]        \n",
      "\t[Step 500] median train step: 957 microseconds\n",
      "\n",
      "Results on batched train:\n",
      "\tMean Loss (#loss): 0.338\n",
      "\tMean Accuracy (#acc): 84.72%\n",
      "Results on test:\n",
      "\tMean Loss (#loss): 0.335\n",
      "\tMean Accuracy (#acc): 85.14%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"io\"\n",
    "    \"time\"\n",
    "\n",
    "    . \"github.com/gomlx/gomlx/graph\"\n",
    "\n",
    "    \"github.com/gomlx/gomlx/examples/adult\"\n",
    "    \"github.com/gomlx/gomlx/examples/notebook/gonb/margaid\"\n",
    "    \"github.com/gomlx/gomlx/ml/context\"\n",
    "    \"github.com/gomlx/gomlx/ml/train\"\n",
    "    \"github.com/gomlx/gomlx/types/shapes\"\n",
    "    \"github.com/gomlx/gomlx/types/slices\"\n",
    "    \"github.com/gomlx/gomlx/types/tensor\"\n",
    "    \"github.com/janpfeifer/gonb/gonbui\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    flagOptimizer      = flag.String(\"optimizer\", \"adam\", \"Type of optimizer to use: 'sgd' or 'adam'\")\n",
    "    flagLearningRate   = flag.Float64(\"learning_rate\", 0.001, \"Initial learning rate.\")\n",
    "    flagCheckpoint     = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    "    flagCheckpointKeep = flag.Int(\"checkpoint_keep\", 10, \"Number of checkpoints to keep, if --checkpoint is set.\")\n",
    "    flagPlots          = flag.Bool(\"plots\", true, \"Plots during training: perform periodic evaluations, \"+\n",
    "                                   \"save results if --checkpoint is set and draw plots, if in a Jupyter notebook.\")\n",
    ")\n",
    "\n",
    "func trainModel() {\n",
    "    // Fixes directories.\n",
    "    *flagDataDir = data.ReplaceTildeInDir(*flagDataDir)\n",
    "    *flagCheckpoint = data.ReplaceTildeInDir(*flagCheckpoint)\n",
    "    if *flagCheckpoint != \"\" && !path.IsAbs(*flagCheckpoint) {\n",
    "        *flagCheckpoint = path.Join(*flagDataDir, *flagCheckpoint)\n",
    "    }\n",
    "\n",
    "    // Load data and create datasets.\n",
    "    adult.LoadAndPreprocessData(*flagDataDir, *flagNumQuantiles, *flagForceDownload, *flagVerbosity)    \n",
    "    trainDS, trainEvalDS, testEvalDS := BuildDatasets(manager)\n",
    "\n",
    "    // Context holds the variables and optionally hyperparameters for the model.\n",
    "    ctx := context.NewContext(manager)\n",
    "    ctx.SetParam(optimizers.LearningRateKey, *flagLearningRate)\n",
    "\n",
    "    // Metrics we are interested.\n",
    "    meanAccuracyMetric := metrics.NewMeanBinaryLogitsAccuracy(\"Mean Accuracy\", \"#acc\")\n",
    "    movingAccuracyMetric := metrics.NewMovingAverageBinaryLogitsAccuracy(\"Moving Average Accuracy\", \"~acc\", 0.01)\n",
    "\n",
    "    // Checkpoints saving.\n",
    "    var checkpoint *checkpoints.Handler\n",
    "    if *flagCheckpoint != \"\" {\n",
    "        var err error\n",
    "        checkpoint, err = checkpoints.Build(ctx).Dir(*flagCheckpoint).Keep(*flagCheckpointKeep).Done()\n",
    "        if err != nil { panic(err) }\n",
    "        fmt.Printf(\"Checkpointing model to %q\\n\", checkpoint.Dir())\n",
    "        globalStep := optimizers.GetGlobalStepVar(ctx).Value().Value().(int)\n",
    "        if globalStep != 0 {\n",
    "            fmt.Printf(\"Restarting training from global_step=%d\\n\", globalStep)\n",
    "        }\n",
    "    }\n",
    "\n",
    "    // Pick a known optimizer.\n",
    "    optimizerFn, found := optimizers.KnownOptimizers[*flagOptimizer]\n",
    "    if !found {\n",
    "        log.Fatalf(\"Unknown optimizer %q, please use one of %v\",\n",
    "            *flagOptimizer, slices.Keys(optimizers.KnownOptimizers))\n",
    "    }\n",
    "\n",
    "    // Create a train.Trainer: this object will orchestrate running the model, feeding\n",
    "    // results to the optimizer, evaluating the metrics, etc. (all happens in trainer.TrainStep)\n",
    "    trainer := train.NewTrainer(manager, ctx, ModelGraph, losses.BinaryCrossentropyLogits,\n",
    "        optimizerFn(),\n",
    "        []metrics.Interface{movingAccuracyMetric}, // trainMetrics\n",
    "        []metrics.Interface{meanAccuracyMetric})   // evalMetrics\n",
    "\n",
    "    // Use standard training loop.\n",
    "    loop := train.NewLoop(trainer)\n",
    "    loop.ReadGlobalStep(ctx)  // Make sure it restarts from previous global step, if one is set.\n",
    "    commandline.AttachProgressBar(loop) // Attaches a progress bar to the loop.\n",
    "\n",
    "    // Attach a checkpoint: checkpoint every 1 minute of training.\n",
    "    if checkpoint != nil {\n",
    "        period := time.Minute * 1\n",
    "        train.PeriodicCallback(loop, period, true, \"saving checkpoint\", 100,\n",
    "            func(loop *train.Loop, metrics []tensor.Tensor) error {\n",
    "                fmt.Printf(\"\\n[saving checkpoint@%d] [median train step (ms): %d]\\n\", loop.LoopStep, loop.MedianTrainStepDuration().Milliseconds())\n",
    "                return checkpoint.Save()\n",
    "            })\n",
    "    }\n",
    "\n",
    "\t// Attach a margaid plots: plot points at exponential steps.\n",
    "    // Points (metrics) are saved along the checkpoint directory (if one is given).\n",
    "\tif *flagPlots {\n",
    "\t\t_ = margaid.NewDefault(loop, checkpoint.Dir(), 100, 1.1, trainEvalDS, testEvalDS)\n",
    "\t}\n",
    "\n",
    "    // Run the given number of steps.\n",
    "    _, err := loop.RunSteps(trainDS, *flagNumSteps)\n",
    "    if err != nil { panic(err) }\n",
    "    fmt.Printf(\"\\t[Step %d] median train step: %d microseconds\\n\", loop.LoopStep, loop.MedianTrainStepDuration().Microseconds())\n",
    "\n",
    "    // Print a final evaluation on train and test datasets.\n",
    "    fmt.Println()\n",
    "    err = commandline.ReportEval(trainer, trainEvalDS, testEvalDS)\n",
    "    if err != nil { panic(err) }\n",
    "    fmt.Println()\n",
    "}\n",
    "\n",
    "// Notice command line flags are passed in the %% notebook command. We set --plot=false here to disable plotting\n",
    "// since this is only a quick test that our train() loop is working. See below the final run for a full training.\n",
    "%% --steps=500 --plots=false\n",
    "trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bb5db6b-3a2c-4f48-8264-f90b22a52ed0",
   "metadata": {},
   "source": [
    "## Final run\n",
    "\n",
    "With everything working, we can do our final run.\n",
    "\n",
    "> **Note** here is where someone might want to hyperparameter tune, trying out different hyperparameters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "66939463-60d7-446f-b4f3-1d60abe7c17c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing model to \"/home/jupyter/work/uci-adult/base_model\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg width=\"1024\" height=\"454\" viewbox=\"0 0 1024 400\" style=\"background-color:#f8f8f8\" preserveAspectRatio=\"xMidYMid meet\" xmlns=\"http://www.w3.org/2000/svg\"><defs><marker markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\"><circle cx=\"5\" cy=\"5\" r=\"3\" fill=\"none\" stroke=\"black\"/></marker><marker markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"filled-circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\"><circle cx=\"5\" cy=\"5\" r=\"3\" fill=\"black\" stroke=\"none\"/></marker><marker markerHeight=\"2%\" id=\"square\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\"><rect fill=\"none\" stroke=\"black\" x=\"2\" y=\"2\" width=\"6\" height=\"6\"/></marker><marker id=\"filled-square\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\"><rect x=\"2\" y=\"2\" width=\"6\" height=\"6\" fill=\"black\" stroke=\"none\"/></marker></defs><g stroke-linejoin=\"round\" fill=\"none\" stroke=\"hsl(90, 47%, 65%)\" transform=\"translate(70 330 )scale(1 -1 )\" stroke-width=\"2px\" stroke-linecap=\"round\" marker-start=\"url(#square)\" marker-mid=\"url(#square)\" marker-end=\"url(#square)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,3.430104e+01 L1.786294e+02,1.700756e+02 L2.773355e+02,1.932431e+02 L3.506075e+02,1.936436e+02 L4.099543e+02,2.116690e+02 L4.607660e+02,2.182699e+02 L5.055983e+02,2.151140e+02 L5.461769e+02,2.289303e+02 L5.835664e+02,2.346791e+02 L6.184621e+02,2.362939e+02 L6.513380e+02,2.435677e+02 L6.825291e+02,2.457820e+02 L7.123676e+02,2.510284e+02 L7.410809e+02,2.518552e+02 L7.688274e+02,2.506976e+02 L7.957190e+02,2.530670e+02 L8.218897e+02,2.532321e+02 L8.474287e+02,2.543879e+02 L8.663200e+02,2.543328e+02 \"/></g><g marker-mid=\"url(#square)\" transform=\"translate(70 330 )scale(1 -1 )\" marker-start=\"url(#square)\" fill=\"none\" stroke=\"hsl(301, 88%, 65%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\" marker-end=\"url(#square)\"><path d=\"M1.768000e+01,4.372222e+01 L1.786294e+02,1.706079e+02 L2.773355e+02,2.003864e+02 L3.506075e+02,2.028898e+02 L4.099543e+02,2.167009e+02 L4.607660e+02,2.223261e+02 L5.055983e+02,2.221014e+02 L5.461769e+02,2.322893e+02 L5.835664e+02,2.374140e+02 L6.184621e+02,2.365239e+02 L6.513380e+02,2.417459e+02 L6.825291e+02,2.448484e+02 L7.123676e+02,2.472820e+02 L7.410809e+02,2.475030e+02 L7.688274e+02,2.451805e+02 L7.957190e+02,2.460656e+02 L8.218897e+02,2.486076e+02 L8.474287e+02,2.490493e+02 L8.663200e+02,2.446270e+02 \" vector-effect=\"non-scaling-stroke\"/></g><g marker-start=\"url(#square)\" marker-mid=\"url(#square)\" fill=\"none\" stroke=\"hsl(152, 76%, 65%)\" transform=\"translate(70 330 )scale(1 -1 )\" marker-end=\"url(#square)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,5.200000e+00 L1.786294e+02,4.427682e+01 L2.773355e+02,1.465910e+02 L3.506075e+02,1.799871e+02 L4.099543e+02,1.999765e+02 L4.607660e+02,2.099569e+02 L5.055983e+02,2.150542e+02 L5.461769e+02,2.219730e+02 L5.835664e+02,2.374717e+02 L6.184621e+02,2.332339e+02 L6.513380e+02,2.372046e+02 L6.825291e+02,2.465225e+02 L7.123676e+02,2.464539e+02 L7.410809e+02,2.548000e+02 L7.688274e+02,2.508908e+02 L7.957190e+02,2.528076e+02 L8.218897e+02,2.527049e+02 L8.474287e+02,2.524566e+02 L8.663200e+02,2.464244e+02 \"/></g><g transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\" stroke=\"black\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,0 L1.768000e+01,-6 M1.680453e+02,0 L1.680453e+02,-6 M2.560033e+02,0 L2.560033e+02,-6 M3.184106e+02,0 L3.184106e+02,-6 M3.668174e+02,0 L3.668174e+02,-6 M4.063686e+02,0 L4.063686e+02,-6 M4.398087e+02,0 L4.398087e+02,-6 M4.687758e+02,0 L4.687758e+02,-6 M4.943267e+02,0 L4.943267e+02,-6 M5.171826e+02,0 L5.171826e+02,-6 M5.378584e+02,0 L5.378584e+02,-6 M6.675479e+02,0 L6.675479e+02,-6 M7.555060e+02,0 L7.555060e+02,-6 M8.179132e+02,0 L8.179132e+02,-6 M8.663200e+02,0 L8.663200e+02,-6 \"/></g><g dominant-baseline=\"hanging\" font-weight=\"normal\" fill=\"black\" stroke-linejoin=\"round\" font-size=\"12px\" text-anchor=\"middle\" stroke=\"black\" stroke-linecap=\"round\" font-style=\"normal\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 1 )\" font-family=\"sans-serif\"><text x=\"1.768000e+01\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">100</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.680453e+02\">200</text><text vector-effect=\"non-scaling-stroke\" x=\"2.560033e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">300</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.184106e+02\">400</text><text vector-effect=\"non-scaling-stroke\" x=\"3.668174e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">500</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.063686e+02\" y=\"10\" dominant-baseline=\"hanging\">600</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.398087e+02\" y=\"10\">700</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.687758e+02\" y=\"10\">800</text><text x=\"4.943267e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">900</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"5.171826e+02\" y=\"10\" dominant-baseline=\"hanging\">1000</text><text vector-effect=\"non-scaling-stroke\" x=\"5.378584e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">1100</text><text vector-effect=\"non-scaling-stroke\" x=\"6.675479e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">2000</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"7.555060e+02\">3000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"8.179132e+02\" y=\"10\" dominant-baseline=\"hanging\">4000</text><text vector-effect=\"non-scaling-stroke\" x=\"8.663200e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">5000</text></g><g stroke-linecap=\"round\" font-family=\"sans-serif\" font-size=\"12px\" text-anchor=\"middle\" fill=\"black\" stroke-linejoin=\"round\" font-style=\"normal\" dominant-baseline=\"baseline\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 1 )rotate(0 0 0 )\" font-weight=\"bold\" stroke=\"black\"><text x=\"442\" y=\"-6\" dominant-baseline=\"baseline\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">Steps</text></g><g font-style=\"normal\" dominant-baseline=\"hanging\" transform=\"translate(70 330 )scale(1 1 )rotate(-90 0 0 )\" text-anchor=\"middle\" fill=\"black\" stroke=\"black\" stroke-linejoin=\"round\" stroke-width=\"2px\" font-family=\"sans-serif\" font-size=\"12px\" font-weight=\"bold\" stroke-linecap=\"round\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"130\" y=\"6\" dominant-baseline=\"hanging\">accuracy</text></g><g fill=\"none\" stroke=\"black\" stroke-linecap=\"round\" text-anchor=\"middle\" stroke-width=\"2px\" font-family=\"sans-serif\" stroke-linejoin=\"round\" font-style=\"normal\" dominant-baseline=\"hanging\" font-size=\"12px\" font-weight=\"bold\"><rect width=\"884\" height=\"260\" vector-effect=\"non-scaling-stroke\" x=\"70\" y=\"70\"/><g dominant-baseline=\"middle\" font-size=\"18px\" fill=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"512\" y=\"35\" dominant-baseline=\"middle\">accuracy metrics</text></g><g fill=\"hsl(90, 47%, 65%)\" stroke=\"hsl(90, 47%, 65%)\" stroke-linecap=\"round\" font-size=\"12px\" stroke-width=\"1px\" font-family=\"sans-serif\" stroke-linejoin=\"round\" font-style=\"normal\" font-weight=\"normal\" text-anchor=\"start\" dominant-baseline=\"hanging\"><rect x=\"76\" y=\"366\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\"/><g fill=\"black\" stroke=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"366\" dominant-baseline=\"hanging\">Eval on batched train: Mean Accuracy</text></g><g stroke-linejoin=\"round\" stroke-width=\"1px\" font-family=\"sans-serif\" font-size=\"12px\" stroke=\"hsl(301, 88%, 65%)\" fill=\"hsl(301, 88%, 65%)\" stroke-linecap=\"round\" font-style=\"normal\" text-anchor=\"start\" font-weight=\"normal\" dominant-baseline=\"hanging\"><rect x=\"76\" y=\"384\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\"/><g fill=\"black\" stroke=\"black\"><text vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"384\" dominant-baseline=\"hanging\" stroke=\"none\">Eval on test: Mean Accuracy</text></g><g font-size=\"12px\" stroke-linejoin=\"round\" font-style=\"normal\" stroke-width=\"1px\" stroke-linecap=\"round\" dominant-baseline=\"hanging\" fill=\"hsl(152, 76%, 65%)\" stroke=\"hsl(152, 76%, 65%)\" font-family=\"sans-serif\" font-weight=\"normal\" text-anchor=\"start\"><rect y=\"402\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\" x=\"76\"/><g fill=\"black\" stroke=\"black\"><text x=\"92\" y=\"402\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">Train: Moving Average Accuracy</text></g></g></g></g></g></svg>\n",
       "<svg height=\"454\" viewbox=\"0 0 1024 400\" style=\"background-color:#f8f8f8\" preserveAspectRatio=\"xMidYMid meet\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1024\"><defs><marker refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"circle\" viewBox=\"0 0 10 10 \"><circle stroke=\"black\" cx=\"5\" cy=\"5\" r=\"3\" fill=\"none\"/></marker><marker refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"filled-circle\" viewBox=\"0 0 10 10 \" refX=\"5\"><circle cx=\"5\" cy=\"5\" r=\"3\" fill=\"black\" stroke=\"none\"/></marker><marker viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"square\"><rect height=\"6\" fill=\"none\" stroke=\"black\" x=\"2\" y=\"2\" width=\"6\"/></marker><marker viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"filled-square\"><rect height=\"6\" fill=\"black\" stroke=\"none\" x=\"2\" y=\"2\" width=\"6\"/></marker></defs><g transform=\"translate(70 330 )scale(1 -1 )\" marker-mid=\"url(#square)\" stroke=\"hsl(90, 47%, 65%)\" stroke-width=\"2px\" marker-end=\"url(#square)\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" marker-start=\"url(#square)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,2.413884e+02 L1.786294e+02,1.344945e+02 L2.773355e+02,1.011308e+02 L3.506075e+02,9.990365e+01 L4.099543e+02,7.582202e+01 L4.607660e+02,6.509897e+01 L5.055983e+02,6.400615e+01 L5.461769e+02,4.545844e+01 L5.835664e+02,3.905278e+01 L6.184621e+02,3.777122e+01 L6.513380e+02,2.599973e+01 L6.825291e+02,2.395019e+01 L7.123676e+02,1.655488e+01 L7.410809e+02,1.329017e+01 L7.688274e+02,1.510667e+01 L7.957190e+02,8.732694e+00 L8.218897e+02,8.186776e+00 L8.474287e+02,5.200000e+00 L8.663200e+02,1.015307e+01 \"/></g><g stroke-width=\"2px\" stroke-linejoin=\"round\" marker-start=\"url(#square)\" marker-mid=\"url(#square)\" marker-end=\"url(#square)\" stroke=\"hsl(301, 88%, 65%)\" stroke-linecap=\"round\" transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,2.383480e+02 L1.786294e+02,1.311953e+02 L2.773355e+02,9.802678e+01 L3.506075e+02,9.665190e+01 L4.099543e+02,7.342942e+01 L4.607660e+02,6.359210e+01 L5.055983e+02,6.272208e+01 L5.461769e+02,4.660241e+01 L5.835664e+02,4.106242e+01 L6.184621e+02,3.975161e+01 L6.513380e+02,2.947588e+01 L6.825291e+02,2.808219e+01 L7.123676e+02,2.115097e+01 L7.410809e+02,1.864688e+01 L7.688274e+02,2.015872e+01 L7.957190e+02,1.543140e+01 L8.218897e+02,1.466199e+01 L8.474287e+02,1.291196e+01 L8.663200e+02,1.747927e+01 \"/></g><g marker-mid=\"url(#square)\" marker-start=\"url(#square)\" transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\" stroke=\"hsl(152, 76%, 65%)\" stroke-linecap=\"round\" marker-end=\"url(#square)\" stroke-width=\"2px\" stroke-linejoin=\"round\"><path d=\"M1.768000e+01,2.548000e+02 L1.786294e+02,2.174052e+02 L2.773355e+02,1.462942e+02 L3.506075e+02,1.152396e+02 L4.099543e+02,9.161702e+01 L4.607660e+02,7.188452e+01 L5.055983e+02,6.459150e+01 L5.461769e+02,5.334497e+01 L5.835664e+02,3.973223e+01 L6.184621e+02,4.202472e+01 L6.513380e+02,3.235992e+01 L6.825291e+02,2.234390e+01 L7.123676e+02,2.081745e+01 L7.410809e+02,1.053377e+01 L7.688274e+02,1.078619e+01 L7.957190e+02,1.020153e+01 L8.218897e+02,1.065730e+01 L8.474287e+02,7.304281e+00 L8.663200e+02,1.175625e+01 \" vector-effect=\"non-scaling-stroke\"/></g><g fill=\"none\" stroke=\"black\" stroke-width=\"2px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" transform=\"translate(70 330 )scale(1 -1 )\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,0 L1.768000e+01,-6 M1.680453e+02,0 L1.680453e+02,-6 M2.560033e+02,0 L2.560033e+02,-6 M3.184106e+02,0 L3.184106e+02,-6 M3.668174e+02,0 L3.668174e+02,-6 M4.063686e+02,0 L4.063686e+02,-6 M4.398087e+02,0 L4.398087e+02,-6 M4.687758e+02,0 L4.687758e+02,-6 M4.943267e+02,0 L4.943267e+02,-6 M5.171826e+02,0 L5.171826e+02,-6 M5.378584e+02,0 L5.378584e+02,-6 M6.675479e+02,0 L6.675479e+02,-6 M7.555060e+02,0 L7.555060e+02,-6 M8.179132e+02,0 L8.179132e+02,-6 M8.663200e+02,0 L8.663200e+02,-6 \"/></g><g font-style=\"normal\" font-size=\"12px\" stroke=\"black\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-weight=\"normal\" text-anchor=\"middle\" transform=\"translate(70 330 )scale(1 1 )\" font-family=\"sans-serif\" fill=\"black\" stroke-width=\"2px\" dominant-baseline=\"hanging\"><text vector-effect=\"non-scaling-stroke\" x=\"1.768000e+01\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">100</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.680453e+02\" y=\"10\" dominant-baseline=\"hanging\">200</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"2.560033e+02\">300</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.184106e+02\" y=\"10\" dominant-baseline=\"hanging\">400</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.668174e+02\">500</text><text x=\"4.063686e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">600</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.398087e+02\">700</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.687758e+02\">800</text><text vector-effect=\"non-scaling-stroke\" x=\"4.943267e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">900</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"5.171826e+02\" y=\"10\" dominant-baseline=\"hanging\">1000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"5.378584e+02\" y=\"10\" dominant-baseline=\"hanging\">1100</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.675479e+02\" y=\"10\">2000</text><text x=\"7.555060e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">3000</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"8.179132e+02\">4000</text><text x=\"8.663200e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">5000</text></g><g text-anchor=\"middle\" stroke-linejoin=\"round\" font-size=\"12px\" stroke=\"black\" font-weight=\"bold\" font-style=\"normal\" transform=\"translate(70 330 )scale(1 1 )rotate(0 0 0 )\" font-family=\"sans-serif\" fill=\"black\" stroke-width=\"2px\" stroke-linecap=\"round\" dominant-baseline=\"baseline\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"442\" y=\"-6\" dominant-baseline=\"baseline\">Steps</text></g><g stroke-linecap=\"round\" font-family=\"sans-serif\" font-size=\"12px\" dominant-baseline=\"baseline\" text-anchor=\"middle\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 -1 )\" fill=\"black\" stroke=\"black\" font-weight=\"bold\" font-style=\"normal\" stroke-linejoin=\"round\"><path d=\"M0,3.581814e+01 L-6,3.581814e+01 M0,1.339111e+02 L-6,1.339111e+02 M0,2.099980e+02 L-6,2.099980e+02 \" vector-effect=\"non-scaling-stroke\"/></g><g fill=\"black\" stroke-width=\"2px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" transform=\"translate(70 330 )scale(1 1 )\" font-weight=\"normal\" font-style=\"normal\" text-anchor=\"end\" stroke=\"black\" font-family=\"sans-serif\" font-size=\"12px\" dominant-baseline=\"middle\"><text y=\"-3.581814e+01\" dominant-baseline=\"middle\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"-10\">0.300</text><text x=\"-10\" y=\"-1.339111e+02\" dominant-baseline=\"middle\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">0.400</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"-10\" y=\"-2.099980e+02\" dominant-baseline=\"middle\">0.500</text></g><g stroke-width=\"2px\" font-style=\"normal\" stroke-linecap=\"round\" fill=\"black\" stroke=\"black\" font-size=\"12px\" font-weight=\"bold\" dominant-baseline=\"hanging\" text-anchor=\"middle\" stroke-linejoin=\"round\" transform=\"translate(70 330 )scale(1 1 )rotate(-90 0 0 )\" font-family=\"sans-serif\"><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"130\" y=\"6\">loss</text></g><g stroke-linejoin=\"round\" font-family=\"sans-serif\" stroke-linecap=\"round\" stroke-width=\"0.5px\" font-weight=\"bold\" dominant-baseline=\"hanging\" font-style=\"normal\" transform=\"translate(70 330 )scale(1 -1 )\" font-size=\"12px\" fill=\"black\" stroke=\"gray\" text-anchor=\"middle\"><path d=\"M0,3.581814e+01 L884,3.581814e+01 M0,1.339111e+02 L884,1.339111e+02 M0,2.099980e+02 L884,2.099980e+02 \" vector-effect=\"non-scaling-stroke\"/></g><g font-style=\"normal\" text-anchor=\"middle\" font-size=\"12px\" stroke-width=\"2px\" font-weight=\"bold\" fill=\"none\" stroke=\"black\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-family=\"sans-serif\" dominant-baseline=\"hanging\"><rect height=\"260\" vector-effect=\"non-scaling-stroke\" x=\"70\" y=\"70\" width=\"884\"/><g fill=\"black\" dominant-baseline=\"middle\" font-size=\"18px\"><text x=\"512\" y=\"35\" dominant-baseline=\"middle\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">loss metrics</text></g><g stroke-linejoin=\"round\" dominant-baseline=\"hanging\" font-style=\"normal\" text-anchor=\"start\" font-size=\"12px\" fill=\"hsl(90, 47%, 65%)\" stroke=\"hsl(90, 47%, 65%)\" stroke-linecap=\"round\" font-family=\"sans-serif\" stroke-width=\"1px\" font-weight=\"normal\"><rect vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"366\" width=\"12\" height=\"12\"/><g fill=\"black\" stroke=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"366\" dominant-baseline=\"hanging\">Eval on batched train: Mean Loss</text></g><g stroke-linejoin=\"round\" font-size=\"12px\" stroke-width=\"1px\" stroke-linecap=\"round\" dominant-baseline=\"hanging\" font-style=\"normal\" font-family=\"sans-serif\" fill=\"hsl(301, 88%, 65%)\" stroke=\"hsl(301, 88%, 65%)\" font-weight=\"normal\" text-anchor=\"start\"><rect vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"384\" width=\"12\" height=\"12\"/><g fill=\"black\" stroke=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"384\" dominant-baseline=\"hanging\">Eval on test: Mean Loss</text></g><g stroke-linecap=\"round\" font-weight=\"normal\" font-family=\"sans-serif\" font-size=\"12px\" fill=\"hsl(152, 76%, 65%)\" stroke=\"hsl(152, 76%, 65%)\" stroke-width=\"1px\" stroke-linejoin=\"round\" dominant-baseline=\"hanging\" font-style=\"normal\" text-anchor=\"start\"><rect vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"402\" width=\"12\" height=\"12\"/><g fill=\"black\" stroke=\"black\"><text y=\"402\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\">Train: Moving Average Loss</text></g></g></g></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (5000 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (544 steps/s)\u001b[0m [loss=0.330] [~loss=0.280] [~acc=86.94%]        \n",
      "\n",
      "[saving checkpoint@5000] [median train step (ms): 0]\n",
      "\t[Step 5000] median train step: 891 microseconds\n",
      "\n",
      "Results on batched train:\n",
      "\tMean Loss (#loss): 0.278\n",
      "\tMean Accuracy (#acc): 87.38%\n",
      "Results on test:\n",
      "\tMean Loss (#loss): 0.284\n",
      "\tMean Accuracy (#acc): 86.84%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% --steps=5000 --checkpoint base_model\n",
    "trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38d8a41-3e9c-4107-a507-c879ef27e3e3",
   "metadata": {},
   "source": [
    "Since the model training went well, and it doesn't seem to be yet terribly overfiting, \n",
    "let's train further, another 15k steps, for 20K steps in total.\t\tmg.WithRange()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "95983f61-2a98-442d-bc5d-896006289a2b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checkpointing model to \"/home/jupyter/work/uci-adult/base_model\"\n",
      "Restarting training from global_step=5000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<svg viewbox=\"0 0 1024 400\" style=\"background-color:#f8f8f8\" preserveAspectRatio=\"xMidYMid meet\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1024\" height=\"454\"><defs><marker markerHeight=\"2%\" id=\"circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\"><circle cy=\"5\" r=\"3\" fill=\"none\" stroke=\"black\" cx=\"5\"/></marker><marker markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"filled-circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\"><circle cx=\"5\" cy=\"5\" r=\"3\" fill=\"black\" stroke=\"none\"/></marker><marker markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"square\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\"><rect height=\"6\" fill=\"none\" stroke=\"black\" x=\"2\" y=\"2\" width=\"6\"/></marker><marker id=\"filled-square\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\"><rect width=\"6\" height=\"6\" fill=\"black\" stroke=\"none\" x=\"2\" y=\"2\"/></marker></defs><g stroke=\"hsl(90, 47%, 65%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" transform=\"translate(70 330 )scale(1 -1 )\" marker-mid=\"url(#square)\" stroke-width=\"2px\" marker-end=\"url(#square)\" fill=\"none\" marker-start=\"url(#square)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,3.386510e+01 L1.365173e+02,1.676057e+02 L2.093971e+02,1.904262e+02 L2.634977e+02,1.908206e+02 L3.073165e+02,2.085760e+02 L3.448334e+02,2.150780e+02 L3.779355e+02,2.119694e+02 L4.078967e+02,2.255787e+02 L4.355033e+02,2.312414e+02 L4.612687e+02,2.328320e+02 L4.855427e+02,2.399969e+02 L5.085726e+02,2.421780e+02 L5.306039e+02,2.473457e+02 L5.518045e+02,2.481602e+02 L5.722912e+02,2.470199e+02 L5.921466e+02,2.493539e+02 L6.114698e+02,2.495165e+02 L6.303266e+02,2.506550e+02 L6.442750e+02,2.506007e+02 L6.487916e+02,2.493539e+02 L6.669114e+02,2.510342e+02 L6.847383e+02,2.512509e+02 L7.023018e+02,2.446825e+02 L7.196363e+02,2.483772e+02 L7.367580e+02,2.508717e+02 L7.536877e+02,2.519009e+02 L7.704470e+02,2.484857e+02 L7.870558e+02,2.511967e+02 L8.035318e+02,2.512509e+02 L8.198887e+02,2.520091e+02 L8.361372e+02,2.517925e+02 L8.522929e+02,2.496250e+02 L8.663200e+02,2.516843e+02 \"/></g><g transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\" marker-end=\"url(#square)\" stroke=\"hsl(301, 88%, 65%)\" stroke-width=\"2px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" marker-start=\"url(#square)\" marker-mid=\"url(#square)\"><path d=\"M1.768000e+01,4.314513e+01 L1.365173e+02,1.681300e+02 L2.093971e+02,1.974624e+02 L2.634977e+02,1.999284e+02 L3.073165e+02,2.135325e+02 L3.448334e+02,2.190734e+02 L3.779355e+02,2.188521e+02 L4.078967e+02,2.288874e+02 L4.355033e+02,2.339353e+02 L4.612687e+02,2.330586e+02 L4.855427e+02,2.382023e+02 L5.085726e+02,2.412584e+02 L5.306039e+02,2.436555e+02 L5.518045e+02,2.438732e+02 L5.722912e+02,2.415854e+02 L5.921466e+02,2.424573e+02 L6.114698e+02,2.449613e+02 L6.303266e+02,2.453963e+02 L6.442750e+02,2.410403e+02 L6.487916e+02,2.481126e+02 L6.669114e+02,2.452876e+02 L6.847383e+02,2.463748e+02 L7.023018e+02,2.428931e+02 L7.196363e+02,2.408222e+02 L7.367580e+02,2.459400e+02 L7.536877e+02,2.477870e+02 L7.704470e+02,2.431109e+02 L7.870558e+02,2.472439e+02 L8.035318e+02,2.485468e+02 L8.198887e+02,2.497401e+02 L8.361372e+02,2.484383e+02 L8.522929e+02,2.426752e+02 L8.663200e+02,2.490893e+02 \" vector-effect=\"non-scaling-stroke\"/></g><g stroke-width=\"2px\" stroke-linecap=\"round\" marker-start=\"url(#square)\" marker-mid=\"url(#square)\" marker-end=\"url(#square)\" transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\" stroke=\"hsl(152, 76%, 65%)\" stroke-linejoin=\"round\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,5.200000e+00 L1.365173e+02,4.369143e+01 L2.093971e+02,1.444729e+02 L2.634977e+02,1.773687e+02 L3.073165e+02,1.970587e+02 L3.448334e+02,2.068895e+02 L3.779355e+02,2.119105e+02 L4.078967e+02,2.187257e+02 L4.355033e+02,2.339921e+02 L4.612687e+02,2.298179e+02 L4.855427e+02,2.337291e+02 L5.085726e+02,2.429074e+02 L5.306039e+02,2.428398e+02 L5.518045e+02,2.510609e+02 L5.722912e+02,2.472102e+02 L5.921466e+02,2.490984e+02 L6.114698e+02,2.489972e+02 L6.303266e+02,2.487526e+02 L6.442750e+02,2.428108e+02 L6.487916e+02,2.476377e+02 L6.669114e+02,2.535516e+02 L6.847383e+02,2.522171e+02 L7.023018e+02,2.468761e+02 L7.196363e+02,2.497729e+02 L7.367580e+02,2.520454e+02 L7.536877e+02,2.541453e+02 L7.704470e+02,2.471888e+02 L7.870558e+02,2.513009e+02 L8.035318e+02,2.537792e+02 L8.198887e+02,2.520161e+02 L8.361372e+02,2.548000e+02 L8.522929e+02,2.508232e+02 L8.663200e+02,2.457898e+02 \"/></g><g transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\" stroke=\"black\" stroke-width=\"2px\" stroke-linecap=\"round\" stroke-linejoin=\"round\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,0 L1.768000e+01,-6 M1.287025e+02,0 L1.287025e+02,-6 M1.936465e+02,0 L1.936465e+02,-6 M2.397250e+02,0 L2.397250e+02,-6 M2.754663e+02,0 L2.754663e+02,-6 M3.046690e+02,0 L3.046690e+02,-6 M3.293596e+02,0 L3.293596e+02,-6 M3.507475e+02,0 L3.507475e+02,-6 M3.696130e+02,0 L3.696130e+02,-6 M3.864888e+02,0 L3.864888e+02,-6 M4.017547e+02,0 L4.017547e+02,-6 M4.975112e+02,0 L4.975112e+02,-6 M5.624552e+02,0 L5.624552e+02,-6 M6.085337e+02,0 L6.085337e+02,-6 M6.442750e+02,0 L6.442750e+02,-6 M6.734777e+02,0 L6.734777e+02,-6 M6.981683e+02,0 L6.981683e+02,-6 M7.195562e+02,0 L7.195562e+02,-6 M7.384217e+02,0 L7.384217e+02,-6 M7.552975e+02,0 L7.552975e+02,-6 M8.663200e+02,0 L8.663200e+02,-6 \"/></g><g font-weight=\"normal\" transform=\"translate(70 330 )scale(1 1 )\" font-size=\"12px\" dominant-baseline=\"hanging\" stroke=\"black\" stroke-width=\"2px\" text-anchor=\"middle\" font-family=\"sans-serif\" font-style=\"normal\" stroke-linecap=\"round\" stroke-linejoin=\"round\" fill=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.768000e+01\" y=\"10\" dominant-baseline=\"hanging\">100</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.287025e+02\" y=\"10\" dominant-baseline=\"hanging\">200</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.936465e+02\" y=\"10\" dominant-baseline=\"hanging\">300</text><text x=\"2.397250e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">400</text><text x=\"2.754663e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">500</text><text x=\"3.046690e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">600</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.293596e+02\" y=\"10\" dominant-baseline=\"hanging\">700</text><text x=\"3.507475e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">800</text><text x=\"3.696130e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">900</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.864888e+02\">1000</text><text x=\"4.017547e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">1100</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.975112e+02\" y=\"10\">2000</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"5.624552e+02\">3000</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.085337e+02\" y=\"10\">4000</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.442750e+02\" y=\"10\">5000</text><text x=\"6.734777e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">6000</text><text x=\"6.981683e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">7000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"7.195562e+02\" y=\"10\" dominant-baseline=\"hanging\">8000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"7.384217e+02\" y=\"10\" dominant-baseline=\"hanging\">9000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"7.552975e+02\" y=\"10\" dominant-baseline=\"hanging\">10000</text><text vector-effect=\"non-scaling-stroke\" x=\"8.663200e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">20000</text></g><g font-size=\"12px\" dominant-baseline=\"baseline\" font-family=\"sans-serif\" font-style=\"normal\" font-weight=\"bold\" stroke=\"black\" stroke-linejoin=\"round\" stroke-linecap=\"round\" transform=\"translate(70 330 )scale(1 1 )rotate(0 0 0 )\" text-anchor=\"middle\" fill=\"black\" stroke-width=\"2px\"><text vector-effect=\"non-scaling-stroke\" x=\"442\" y=\"-6\" dominant-baseline=\"baseline\" stroke=\"none\">Steps</text></g><g font-style=\"normal\" font-weight=\"bold\" font-family=\"sans-serif\" stroke=\"black\" font-size=\"12px\" stroke-linejoin=\"round\" transform=\"translate(70 330 )scale(1 1 )rotate(-90 0 0 )\" dominant-baseline=\"hanging\" fill=\"black\" text-anchor=\"middle\" stroke-width=\"2px\" stroke-linecap=\"round\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"130\" y=\"6\" dominant-baseline=\"hanging\">accuracy</text></g><g stroke-linejoin=\"round\" font-size=\"12px\" dominant-baseline=\"hanging\" text-anchor=\"middle\" font-family=\"sans-serif\" stroke=\"black\" stroke-linecap=\"round\" fill=\"none\" font-style=\"normal\" font-weight=\"bold\" stroke-width=\"2px\"><rect width=\"884\" height=\"260\" vector-effect=\"non-scaling-stroke\" x=\"70\" y=\"70\"/><g font-size=\"18px\" dominant-baseline=\"middle\" fill=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"512\" y=\"35\" dominant-baseline=\"middle\">accuracy metrics</text></g><g stroke-width=\"1px\" font-size=\"12px\" dominant-baseline=\"hanging\" font-style=\"normal\" text-anchor=\"start\" font-family=\"sans-serif\" stroke-linecap=\"round\" stroke-linejoin=\"round\" fill=\"hsl(90, 47%, 65%)\" stroke=\"hsl(90, 47%, 65%)\" font-weight=\"normal\"><rect y=\"366\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\" x=\"76\"/><g fill=\"black\" stroke=\"black\"><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"366\">Eval on batched train: Mean Accuracy</text></g><g stroke=\"hsl(301, 88%, 65%)\" font-style=\"normal\" font-family=\"sans-serif\" dominant-baseline=\"hanging\" fill=\"hsl(301, 88%, 65%)\" font-weight=\"normal\" text-anchor=\"start\" stroke-width=\"1px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-size=\"12px\"><rect vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"384\" width=\"12\" height=\"12\"/><g fill=\"black\" stroke=\"black\"><text y=\"384\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\">Eval on test: Mean Accuracy</text></g><g text-anchor=\"start\" dominant-baseline=\"hanging\" stroke=\"hsl(152, 76%, 65%)\" stroke-width=\"1px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-family=\"sans-serif\" font-style=\"normal\" font-weight=\"normal\" fill=\"hsl(152, 76%, 65%)\" font-size=\"12px\"><rect width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"402\"/><g fill=\"black\" stroke=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"402\" dominant-baseline=\"hanging\">Train: Moving Average Accuracy</text></g></g></g></g></g></svg>\n",
       "<svg style=\"background-color:#f8f8f8\" preserveAspectRatio=\"xMidYMid meet\" xmlns=\"http://www.w3.org/2000/svg\" width=\"1024\" height=\"454\" viewbox=\"0 0 1024 400\"><defs><marker id=\"circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\"><circle fill=\"none\" stroke=\"black\" cx=\"5\" cy=\"5\" r=\"3\"/></marker><marker markerHeight=\"2%\" id=\"filled-circle\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\"><circle cy=\"5\" r=\"3\" fill=\"black\" stroke=\"none\" cx=\"5\"/></marker><marker markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"square\" viewBox=\"0 0 10 10 \" refX=\"5\" refY=\"5\"><rect x=\"2\" y=\"2\" width=\"6\" height=\"6\" fill=\"none\" stroke=\"black\"/></marker><marker refX=\"5\" refY=\"5\" markerUnits=\"userSpaceOnUse\" markerWidth=\"2%\" markerHeight=\"2%\" id=\"filled-square\" viewBox=\"0 0 10 10 \"><rect height=\"6\" fill=\"black\" stroke=\"none\" x=\"2\" y=\"2\" width=\"6\"/></marker></defs><g fill=\"none\" stroke-linejoin=\"round\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 -1 )\" marker-mid=\"url(#square)\" stroke=\"hsl(90, 47%, 65%)\" stroke-linecap=\"round\" marker-start=\"url(#square)\" marker-end=\"url(#square)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,2.419981e+02 L1.365173e+02,1.399635e+02 L2.093971e+02,1.081165e+02 L2.634977e+02,1.069451e+02 L3.073165e+02,8.395823e+01 L3.448334e+02,7.372265e+01 L3.779355e+02,7.267950e+01 L4.078967e+02,5.497496e+01 L4.355033e+02,4.886049e+01 L4.612687e+02,4.763720e+01 L4.855427e+02,3.640083e+01 L5.085726e+02,3.444446e+01 L5.306039e+02,2.738533e+01 L5.518045e+02,2.426904e+01 L5.722912e+02,2.600296e+01 L5.921466e+02,1.991874e+01 L6.114698e+02,1.939764e+01 L6.303266e+02,1.654664e+01 L6.442750e+02,2.127454e+01 L6.487916e+02,1.598581e+01 L6.669114e+02,1.471302e+01 L6.847383e+02,1.440918e+01 L7.023018e+02,1.850527e+01 L7.196363e+02,1.470110e+01 L7.367580e+02,1.201894e+01 L7.536877e+02,1.150482e+01 L7.704470e+02,1.497038e+01 L7.870558e+02,1.120825e+01 L8.035318e+02,1.020808e+01 L8.198887e+02,1.111580e+01 L8.361372e+02,9.234958e+00 L8.522929e+02,1.070660e+01 L8.663200e+02,8.873012e+00 \"/></g><g stroke-linecap=\"round\" stroke-width=\"2px\" marker-end=\"url(#square)\" stroke-linejoin=\"round\" marker-mid=\"url(#square)\" transform=\"translate(70 330 )scale(1 -1 )\" marker-start=\"url(#square)\" fill=\"none\" stroke=\"hsl(301, 88%, 65%)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,2.390959e+02 L1.365173e+02,1.368143e+02 L2.093971e+02,1.051536e+02 L2.634977e+02,1.038412e+02 L3.073165e+02,8.167439e+01 L3.448334e+02,7.228428e+01 L3.779355e+02,7.145380e+01 L4.078967e+02,5.606692e+01 L4.355033e+02,5.077878e+01 L4.612687e+02,4.952756e+01 L4.855427e+02,3.971896e+01 L5.085726e+02,3.838862e+01 L5.306039e+02,3.177249e+01 L5.518045e+02,2.938223e+01 L5.722912e+02,3.082535e+01 L5.921466e+02,2.631293e+01 L6.114698e+02,2.557850e+01 L6.303266e+02,2.390802e+01 L6.442750e+02,2.826771e+01 L6.487916e+02,2.345613e+01 L6.669114e+02,2.341938e+01 L6.847383e+02,2.282157e+01 L7.023018e+02,2.582978e+01 L7.196363e+02,2.399684e+01 L7.367580e+02,2.160123e+01 L7.536877e+02,2.135642e+01 L7.704470e+02,2.396237e+01 L7.870558e+02,2.032026e+01 L8.035318e+02,2.000397e+01 L8.198887e+02,2.026351e+01 L8.361372e+02,1.998213e+01 L8.522929e+02,2.247190e+01 L8.663200e+02,2.148935e+01 \"/></g><g stroke-linejoin=\"round\" marker-mid=\"url(#square)\" marker-end=\"url(#square)\" transform=\"translate(70 330 )scale(1 -1 )\" stroke-width=\"2px\" marker-start=\"url(#square)\" stroke-linecap=\"round\" fill=\"none\" stroke=\"hsl(152, 76%, 65%)\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,2.548000e+02 L1.365173e+02,2.191052e+02 L2.093971e+02,1.512268e+02 L2.634977e+02,1.215839e+02 L3.073165e+02,9.903521e+01 L3.448334e+02,8.019973e+01 L3.779355e+02,7.323824e+01 L4.078967e+02,6.250297e+01 L4.355033e+02,4.950905e+01 L4.612687e+02,5.169733e+01 L4.855427e+02,4.247189e+01 L5.085726e+02,3.291119e+01 L5.306039e+02,3.145413e+01 L5.518045e+02,2.163794e+01 L5.722912e+02,2.187889e+01 L5.921466e+02,2.132080e+01 L6.114698e+02,2.175586e+01 L6.303266e+02,1.855526e+01 L6.442750e+02,2.280485e+01 L6.487916e+02,2.034714e+01 L6.669114e+02,1.195276e+01 L6.847383e+02,1.649878e+01 L7.023018e+02,2.056599e+01 L7.196363e+02,1.508648e+01 L7.367580e+02,1.178160e+01 L7.536877e+02,5.200000e+00 L7.704470e+02,1.435431e+01 L7.870558e+02,1.281370e+01 L8.035318e+02,1.021031e+01 L8.198887e+02,7.830605e+00 L8.361372e+02,7.182762e+00 L8.522929e+02,1.100709e+01 L8.663200e+02,1.465621e+01 \"/></g><g stroke=\"black\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 -1 )\" fill=\"none\"><path vector-effect=\"non-scaling-stroke\" d=\"M1.768000e+01,0 L1.768000e+01,-6 M1.287025e+02,0 L1.287025e+02,-6 M1.936465e+02,0 L1.936465e+02,-6 M2.397250e+02,0 L2.397250e+02,-6 M2.754663e+02,0 L2.754663e+02,-6 M3.046690e+02,0 L3.046690e+02,-6 M3.293596e+02,0 L3.293596e+02,-6 M3.507475e+02,0 L3.507475e+02,-6 M3.696130e+02,0 L3.696130e+02,-6 M3.864888e+02,0 L3.864888e+02,-6 M4.017547e+02,0 L4.017547e+02,-6 M4.975112e+02,0 L4.975112e+02,-6 M5.624552e+02,0 L5.624552e+02,-6 M6.085337e+02,0 L6.085337e+02,-6 M6.442750e+02,0 L6.442750e+02,-6 M6.734777e+02,0 L6.734777e+02,-6 M6.981683e+02,0 L6.981683e+02,-6 M7.195562e+02,0 L7.195562e+02,-6 M7.384217e+02,0 L7.384217e+02,-6 M7.552975e+02,0 L7.552975e+02,-6 M8.663200e+02,0 L8.663200e+02,-6 \"/></g><g stroke-width=\"2px\" font-size=\"12px\" text-anchor=\"middle\" fill=\"black\" stroke-linejoin=\"round\" font-weight=\"normal\" transform=\"translate(70 330 )scale(1 1 )\" dominant-baseline=\"hanging\" stroke=\"black\" stroke-linecap=\"round\" font-family=\"sans-serif\" font-style=\"normal\"><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.768000e+01\">100</text><text vector-effect=\"non-scaling-stroke\" x=\"1.287025e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">200</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"1.936465e+02\">300</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"2.397250e+02\" y=\"10\" dominant-baseline=\"hanging\">400</text><text x=\"2.754663e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">500</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.046690e+02\" y=\"10\" dominant-baseline=\"hanging\">600</text><text vector-effect=\"non-scaling-stroke\" x=\"3.293596e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">700</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.507475e+02\" y=\"10\" dominant-baseline=\"hanging\">800</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.696130e+02\" y=\"10\">900</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"3.864888e+02\">1000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.017547e+02\" y=\"10\" dominant-baseline=\"hanging\">1100</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"4.975112e+02\">2000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"5.624552e+02\" y=\"10\" dominant-baseline=\"hanging\">3000</text><text x=\"6.085337e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">4000</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.442750e+02\" y=\"10\">5000</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.734777e+02\">6000</text><text dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"6.981683e+02\" y=\"10\">7000</text><text y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"7.195562e+02\">8000</text><text x=\"7.384217e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">9000</text><text vector-effect=\"non-scaling-stroke\" x=\"7.552975e+02\" y=\"10\" dominant-baseline=\"hanging\" stroke=\"none\">10000</text><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"8.663200e+02\" y=\"10\" dominant-baseline=\"hanging\">20000</text></g><g font-size=\"12px\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 1 )rotate(0 0 0 )\" text-anchor=\"middle\" dominant-baseline=\"baseline\" font-weight=\"bold\" fill=\"black\" stroke=\"black\" font-family=\"sans-serif\" font-style=\"normal\"><text y=\"-6\" dominant-baseline=\"baseline\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"442\">Steps</text></g><g text-anchor=\"middle\" fill=\"black\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-family=\"sans-serif\" font-style=\"normal\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 -1 )\" font-weight=\"bold\" stroke=\"black\" font-size=\"12px\" dominant-baseline=\"baseline\"><path vector-effect=\"non-scaling-stroke\" d=\"M0,4.577290e+01 L-6,4.577290e+01 M0,1.394067e+02 L-6,1.394067e+02 M0,2.120347e+02 L-6,2.120347e+02 \"/></g><g font-style=\"normal\" font-weight=\"normal\" fill=\"black\" stroke-linecap=\"round\" dominant-baseline=\"middle\" stroke-linejoin=\"round\" font-family=\"sans-serif\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 1 )\" font-size=\"12px\" stroke=\"black\" text-anchor=\"end\"><text dominant-baseline=\"middle\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"-10\" y=\"-4.577290e+01\">0.300</text><text dominant-baseline=\"middle\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"-10\" y=\"-1.394067e+02\">0.400</text><text vector-effect=\"non-scaling-stroke\" x=\"-10\" y=\"-2.120347e+02\" dominant-baseline=\"middle\" stroke=\"none\">0.500</text></g><g stroke-linecap=\"round\" stroke-linejoin=\"round\" font-family=\"sans-serif\" font-style=\"normal\" dominant-baseline=\"hanging\" stroke-width=\"2px\" transform=\"translate(70 330 )scale(1 1 )rotate(-90 0 0 )\" font-weight=\"bold\" fill=\"black\" stroke=\"black\" font-size=\"12px\" text-anchor=\"middle\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"130\" y=\"6\" dominant-baseline=\"hanging\">loss</text></g><g font-weight=\"bold\" stroke=\"gray\" stroke-linecap=\"round\" stroke-width=\"0.5px\" transform=\"translate(70 330 )scale(1 -1 )\" font-size=\"12px\" text-anchor=\"middle\" dominant-baseline=\"hanging\" fill=\"black\" stroke-linejoin=\"round\" font-family=\"sans-serif\" font-style=\"normal\"><path vector-effect=\"non-scaling-stroke\" d=\"M0,4.577290e+01 L884,4.577290e+01 M0,1.394067e+02 L884,1.394067e+02 M0,2.120347e+02 L884,2.120347e+02 \"/></g><g font-family=\"sans-serif\" font-style=\"normal\" font-weight=\"bold\" font-size=\"12px\" text-anchor=\"middle\" fill=\"none\" stroke-linecap=\"round\" stroke-linejoin=\"round\" stroke-width=\"2px\" dominant-baseline=\"hanging\" stroke=\"black\"><rect height=\"260\" vector-effect=\"non-scaling-stroke\" x=\"70\" y=\"70\" width=\"884\"/><g font-size=\"18px\" fill=\"black\" dominant-baseline=\"middle\"><text vector-effect=\"non-scaling-stroke\" x=\"512\" y=\"35\" dominant-baseline=\"middle\" stroke=\"none\">loss metrics</text></g><g text-anchor=\"start\" font-weight=\"normal\" fill=\"hsl(90, 47%, 65%)\" stroke=\"hsl(90, 47%, 65%)\" stroke-linecap=\"round\" stroke-linejoin=\"round\" font-size=\"12px\" dominant-baseline=\"hanging\" font-family=\"sans-serif\" font-style=\"normal\" stroke-width=\"1px\"><rect x=\"76\" y=\"366\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\"/><g fill=\"black\" stroke=\"black\"><text stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\" y=\"366\" dominant-baseline=\"hanging\">Eval on batched train: Mean Loss</text></g><g fill=\"hsl(301, 88%, 65%)\" stroke=\"hsl(301, 88%, 65%)\" stroke-linecap=\"round\" font-style=\"normal\" font-weight=\"normal\" stroke-width=\"1px\" stroke-linejoin=\"round\" font-family=\"sans-serif\" font-size=\"12px\" text-anchor=\"start\" dominant-baseline=\"hanging\"><rect x=\"76\" y=\"384\" width=\"12\" height=\"12\" vector-effect=\"non-scaling-stroke\"/><g stroke=\"black\" fill=\"black\"><text x=\"92\" y=\"384\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\">Eval on test: Mean Loss</text></g><g stroke=\"hsl(152, 76%, 65%)\" text-anchor=\"start\" dominant-baseline=\"hanging\" stroke-linejoin=\"round\" font-family=\"sans-serif\" fill=\"hsl(152, 76%, 65%)\" stroke-width=\"1px\" font-size=\"12px\" font-style=\"normal\" font-weight=\"normal\" stroke-linecap=\"round\"><rect vector-effect=\"non-scaling-stroke\" x=\"76\" y=\"402\" width=\"12\" height=\"12\"/><g fill=\"black\" stroke=\"black\"><text y=\"402\" dominant-baseline=\"hanging\" stroke=\"none\" vector-effect=\"non-scaling-stroke\" x=\"92\">Train: Moving Average Loss</text></g></g></g></g></g></svg>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (15000 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (816 steps/s)\u001b[0m [loss=0.242] [~loss=0.273] [~acc=87.11%]        \n",
      "\n",
      "[saving checkpoint@20000] [median train step (ms): 0]\n",
      "\t[Step 20000] median train step: 894 microseconds\n",
      "\n",
      "Results on batched train:\n",
      "\tMean Loss (#loss): 0.268\n",
      "\tMean Accuracy (#acc): 87.44%\n",
      "Results on test:\n",
      "\tMean Loss (#loss): 0.278\n",
      "\tMean Accuracy (#acc): 87.29%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% --steps=15000 --checkpoint base_model\n",
    "trainModel()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.21.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
