{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f431da81-4d94-4fd1-8a51-952ef824cb46",
   "metadata": {},
   "source": [
    "# IMDB Movie Review Dataset\n",
    "\n",
    "This is a library to download and parse the [IMDB's Large Movie Review Dataset](http://ai.stanford.edu/~amaas/data/sentiment/) dataset and a demo of a transformer based model. The dataset has 25K training, and 25K test dataset, plus 50K unlabeled examples.\n",
    "\n",
    "It's inspired on [Keras' Text classification with Transformer](https://keras.io/examples/nlp/text_classification_with_transformer/) demo.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "392f19ad-caa7-4d7d-8078-cbca680f2be2",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "32600e05-745d-4c38-999a-3b96ca1502cc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gopjrt\" to local directory \"/home/janpf/Projects/gopjrt\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/bsplines\" to local directory \"/home/janpf/Projects/bsplines\".\n",
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/janpf/Projects/gomlx\".\n",
      "\t- Added replace rule for module \"github.com/janpfeifer/gonb\" to local directory \"/home/janpf/Projects/gonb\".\n"
     ]
    }
   ],
   "source": [
    "!*rm -f go.work && go work init && go work use . \"${HOME}/Projects/gomlx\" \"${HOME}/Projects/gonb\" \"${HOME}/Projects/gopjrt\" \"${HOME}/Projects/bsplines\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "443e9e56-ef12-4d04-b7bb-99478fa2b662",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Downloading data files\n",
    "\n",
    "To download, uncompress and untar to the local directory, simply do the following. Notice if it's already downloaded in the given `--data` directory, it returns immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e98ca191-0d4b-4e7c-ab24-ded6991b9671",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"github.com/gomlx/gomlx/examples/imdb\"\n",
    "    \"github.com/gomlx/gomlx/ml/data\"\n",
    "    \"github.com/janpfeifer/must\"\n",
    "\n",
    "    _ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "\tflagDataDir    = flag.String(\"data\", \"~/tmp/imdb\", \"Directory to cache downloaded and generated dataset files.\")\n",
    "\tflagEval       = flag.Bool(\"eval\", true, \"Whether to evaluate the model on the validation data in the end.\")\n",
    "\tflagVerbosity  = flag.Int(\"verbosity\", 1, \"Level of verbosity, the higher the more verbose.\")\n",
    "\tflagCheckpoint = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    ")\n",
    "\n",
    "func AssertDownloaded() {\n",
    "    *flagDataDir = data.ReplaceTildeInDir(*flagDataDir)\n",
    "    if !data.FileExists(*flagDataDir) {\n",
    "        must.M(os.MkdirAll(*flagDataDir, 0777))\n",
    "    }\n",
    "    must.M(imdb.Download(*flagDataDir))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41a415e2-8a29-4aeb-8809-b8d6b7ede5ad",
   "metadata": {},
   "source": [
    "### Sampling some examples\n",
    "\n",
    "It creates a small dataset and print out some random examples.\n",
    "\n",
    "It also defines the `DType`, used for all internal representations of the model, and the flag `--max_len` that defines the maximum number of tokens used per observation. This will beused in the modeling later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f2bf2aab-7d50-4110-a8e3-bbee08063521",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 0 - label 1]                                    │\n",
      "│    a novel by the same title written by louis de           │\n",
      "│    bernieres this wonderful historical novel tells the     │\n",
      "│    story of beautiful pelagia daughter of doctor and       │\n",
      "│    their life on kefalonia during wwii pelagia s           │\n",
      "│    fiancee local fisherman mandras enlists when the        │\n",
      "│    italian army invades northern greece from albania       │\n",
      "│    under false pretenses when the axis finally prevails    │\n",
      "│    with a lot of help from the germans a garrison of       │\n",
      "│    italian soldiers is stationed on the island and         │\n",
      "│    captain corelli plays a big part in keeping the         │\n",
      "│    occupation a peaceful time as mandras joins the         │\n",
      "│    partisans charming corelli and his mandolin are         │\n",
      "│    quartered with the doctor and his beautiful daughter    │\n",
      "│    of course this makes it a novel about love but it is    │\n",
      "│    also a war novel a summary of greek history a tale      │\n",
      "│    of communist uprising in post war greece a portrait     │\n",
      "│    of the madness of mussolini and most importantly an     │\n",
      "│    ode to island life on kefalonia some of these           │\n",
      "│    elements return in the movie but in general it is an    │\n",
      "│    impossible book to film i am glad nobody ever tried     │\n",
      "│    the movie captain corelli s mandolin however is         │\n",
      "│    worth seeing just make sure you read the book after     │\n",
      "│    you see the movie                                       │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 1 - label 0]                                    │\n",
      "│    <START> harry knowles has a quote right on the front    │\n",
      "│    cover of the dvd stating the next icon of horror        │\n",
      "│    really i have heard a lot of hype surrounding this      │\n",
      "│    one but wasn t totally convinced however i am a die     │\n",
      "│    hard horror fan and will give just about any horror     │\n",
      "│    movie a chance no matter the budget or the rating       │\n",
      "│    cause ya never know where your gonna find the next      │\n",
      "│    gem not here not hatchet hatchet is poorly conceived    │\n",
      "│    poorly acted and un funny just because you have the     │\n",
      "│    actors who played freddy jason and candyman and a       │\n",
      "│    buffy chic topless with tons of gore does not make      │\n",
      "│    you an expert on horror sorry i don t even want to      │\n",
      "│    describe the plot because it is so idiotic honestly     │\n",
      "│    my money is on rob zombie there is a man who knows      │\n",
      "│    old school horror forget this trash                     │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "┌────────────────────────────────────────────────────────────┐\n",
      "│                                                            │\n",
      "│    [Sample 2 - label 0]                                    │\n",
      "│    <START> when this show first aired i will admit to      │\n",
      "│    being intrigued by the premise and the setting with     │\n",
      "│    an open mind i watched the first two episodes and       │\n",
      "│    naturally dismissed it as being destined to run for     │\n",
      "│    a half season at most i happened to be watching a e     │\n",
      "│    recently and witnessed an ad for this garbage and i     │\n",
      "│    could barely contain my surprise i truly hope people    │\n",
      "│    are watching this for a laugh and not taking it         │\n",
      "│    seriously the characters are truly some of the most     │\n",
      "│    ridiculous and outright laughable on television         │\n",
      "│    scripted or otherwise it s obviously generating         │\n",
      "│    ratings so i must give the creators credit for          │\n",
      "│    establishing and maintaining a fanbase but i            │\n",
      "│    seriously hope no one is watching this under any        │\n",
      "│    pretense of seriousness                                 │\n",
      "│                                                            │\n",
      "│                                                            │\n",
      "└────────────────────────────────────────────────────────────┘\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import \"github.com/gomlx/gomlx/examples/imdb\"\n",
    "\n",
    "%%\n",
    "AssertDownloaded()\n",
    "imdb.PrintSample(3)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cb8ca01-2c8f-4cd8-a644-850e928f64e1",
   "metadata": {},
   "source": [
    "## Training\n",
    "\n",
    "We will create 3 different types of models for this demo: **Bag of Words** (**\"bow\"**), **Convolutionals** (**\"cnn\"**) and **Transformers** (**\"transformer\"**).\n",
    "\n",
    "### Model Configuration\n",
    "\n",
    "As with other demos we leverage the `context.Context` object to store all model and training parameters. \n",
    "One can set specific parameters using the `-set` command line flag.\n",
    "\n",
    "The [`imdb.CreateDefaultContext()`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/train.go) method sets all the default values for the hyperparameters that may be used by any of the 3 model types. The parameter \"model\" specify the model type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ad068f5e-46d9-411b-823c-0eae905da41c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model types: [\"bow\" \"cnn\" \"transformer\"]\n",
      "Context hyperparameters:\n",
      "\t\"activation\": (string) \n",
      "\t\"adam_dtype\": (string) \n",
      "\t\"adam_epsilon\": (float64) 1e-07\n",
      "\t\"batch_size\": (int) 32\n",
      "\t\"cnn_dropout_rate\": (float64) 0.5\n",
      "\t\"cnn_normalization\": (string) \n",
      "\t\"cnn_num_layers\": (float64) 5\n",
      "\t\"cosine_schedule_steps\": (int) 0\n",
      "\t\"dropout_rate\": (float64) 0.1\n",
      "\t\"eval_batch_size\": (int) 200\n",
      "\t\"fnn_dropout_rate\": (float64) 0.3\n",
      "\t\"fnn_normalization\": (string) \n",
      "\t\"fnn_num_hidden_layers\": (int) 2\n",
      "\t\"fnn_num_hidden_nodes\": (int) 32\n",
      "\t\"fnn_residual\": (bool) true\n",
      "\t\"imdb_content_max_len\": (int) 200\n",
      "\t\"imdb_include_separators\": (bool) false\n",
      "\t\"imdb_mask_word_task_weight\": (float64) 0\n",
      "\t\"imdb_max_vocab\": (int) 20000\n",
      "\t\"imdb_token_embedding_size\": (int) 32\n",
      "\t\"imdb_use_unsupervised\": (bool) false\n",
      "\t\"imdb_word_dropout_rate\": (float64) 0\n",
      "\t\"l1_regularization\": (float64) 0\n",
      "\t\"l2_regularization\": (float64) 0\n",
      "\t\"learning_rate\": (float64) 0.0001\n",
      "\t\"model\": (string) cnn\n",
      "\t\"normalization\": (string) layer\n",
      "\t\"num_checkpoints\": (int) 3\n",
      "\t\"optimizer\": (string) adamw\n",
      "\t\"plots\": (bool) true\n",
      "\t\"train_steps\": (int) 5000\n",
      "\t\"transformer_att_key_size\": (int) 8\n",
      "\t\"transformer_dropout_rate\": (float64) -1\n",
      "\t\"transformer_max_att_len\": (int) 200\n",
      "\t\"transformer_num_att_heads\": (int) 2\n",
      "\t\"transformer_num_att_layers\": (int) 1\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"golang.org/x/exp/maps\"\n",
    "    \"github.com/gomlx/gomlx/ml/context\"\n",
    ")\n",
    "\n",
    "// settings is bound to a \"-set\" flag to be used to set context hyperparameters.\n",
    "var settings = commandline.CreateContextSettingsFlag(imdb.CreateDefaultContext(), \"set\")\n",
    "\n",
    "// ContextFromSettings is the default context (createDefaultContext) changed by -set flag.\n",
    "// It also returns the list of parameters changed by -set in paramsSet: we use this later to avoid loading over the values from checkpoints.\n",
    "func ContextFromSettings() (ctx *context.Context, paramsSet []string) {\n",
    "    ctx = imdb.CreateDefaultContext()\n",
    "    paramsSet = must.M1(commandline.ParseContextSettings(ctx, *settings))\n",
    "    return ctx, paramsSet\n",
    "}\n",
    "\n",
    "%% -set=\"model=cnn\"\n",
    "fmt.Printf(\"Model types: %q\\n\", maps.Keys(imdb.ValidModels))\n",
    "ctx, _ := ContextFromSettings()\n",
    "fmt.Println(commandline.SprintContextSettings(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9eb816-6caf-46ea-805c-bd375834c55b",
   "metadata": {},
   "source": [
    "### Bag Of Words Model (bow)\n",
    "\n",
    "This is the simplest model we are going to train: it embeds each token of the sentence (default size of the is 32 numbers) sum them up, and pass that through a FNN.\n",
    "\n",
    "The [code in `imdb.BagOfWordsModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_bagofwords.go) looks like this:\n",
    "\n",
    "```go\n",
    "// BagOfWordsModelGraph builds the computation graph for the \"bag of words\" model: simply the sum of the embeddings\n",
    "// for each token included.\n",
    "func BagOfWordsModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tembed, _ := EmbedTokensGraph(ctx, inputs[0])\n",
    "\n",
    "\t// Take the max over the content length, and put an FNN on top.\n",
    "\t// Shape transformation: [batch_size, content_len, embed_size] -> [batch_size, embed_size]\n",
    "\tembed = ReduceMax(embed, 1)\n",
    "\tlogits := fnn.New(ctx, embed, 1).Done()\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "```\n",
    "\n",
    "We played a bit with the hyperparameters to get to ~85% accuracy on the validation data.\n",
    "\n",
    "The [code for `imdb.TrainModel` is here](https://github.com/gomlx/gomlx/blob/main/examples/imdb/train.go).\n",
    "It's a straight forward GoMLX training loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "50cd517a-f592-4319-a9fd-acb8ab78124c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"xla\":\txla:cuda - PJRT \"cuda\" plugin (/usr/local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.54\n",
      "Model: bow\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (10000 steps):    7% [\u001b[32m=\u001b[0m\u001b[32m>\u001b[0m......................................] (135 steps/s) [5s:1m8s]\u001b[0m [step=719] [loss+=0.689] [~loss+=0.692] [~loss=0.692] [~acc=54.07%]         "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (10000 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (162 steps/s)\u001b[0m [step=9999] [loss+=0.441] [~loss+=0.353] [~loss=0.338] [~acc=85.56%]         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"2d33184b\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.547007143497467,0.4792057275772095,0.5407835841178894,0.6519935131072998,0.712973415851593,0.7575789093971252,0.7727317810058594,0.7986283898353577,0.8122482299804688,0.8159536719322205,0.8307754993438721,0.8434639573097229,0.857994794845581,0.8556119799613953]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.5,0.5,0.5029999613761902,0.7662400007247925,0.7940799593925476,0.8123599886894226,0.8297199606895447,0.8459599614143372,0.857759952545166,0.8675999641418457,0.8802799582481384,0.8916399478912354,0.9053199887275696,0.906719982624054]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.5,0.5,0.5015199780464172,0.7518399953842163,0.7785599827766418,0.7945999503135681,0.8084799647331238,0.8185199499130249,0.8273999691009521,0.8340399861335754,0.8392399549484253,0.8436399698257446,0.8483999967575073,0.8479999899864197]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('2d33184b', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"bd937d26\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6937408447265625,0.6951113343238831,0.6925460696220398,0.6842464208602905,0.6012482643127441,0.4233246147632599,0.45784348249435425,0.41578158736228943,0.5162700414657593,0.5628408193588257,0.49449434876441956,0.41073739528656006,0.2979934513568878,0.4414035975933075]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6925793886184692,0.6944131851196289,0.6920109391212463,0.6869666576385498,0.6420679688453674,0.530301034450531,0.4920032024383545,0.45240047574043274,0.4333447515964508,0.41640615463256836,0.39538607001304626,0.37467819452285767,0.34281855821609497,0.35284027457237244]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6912480592727661,0.6935752630233765,0.6914365291595459,0.6862096786499023,0.6384869813919067,0.5197030305862427,0.478680282831192,0.4382016360759735,0.41863641142845154,0.40157225728034973,0.3808433413505554,0.35997408628463745,0.32815104722976685,0.33824077248573303]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6944460868835449,0.6929221153259277,0.691224992275238,0.6826053857803345,0.6109962463378906,0.48199519515037537,0.4297032952308655,0.3950510025024414,0.36628687381744385,0.3414905071258545,0.3195304870605469,0.29437264800071716,0.27006614208221436,0.26771920919418335]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.693331241607666,0.6922543048858643,0.6906942129135132,0.6816650032997131,0.6061425805091858,0.470414400100708,0.4161984324455261,0.3807152509689331,0.35153189301490784,0.3266720771789551,0.304970920085907,0.2796972692012787,0.2553769648075104,0.25313806533813477]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6944599747657776,0.6929857730865479,0.6914761662483215,0.6833863854408264,0.6166284084320068,0.49871811270713806,0.45532214641571045,0.4292457401752472,0.4095883071422577,0.3942773640155792,0.38334187865257263,0.3717249929904938,0.3632521331310272,0.36324620246887207]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6933450698852539,0.6923179626464844,0.6909462213516235,0.682445764541626,0.6117748022079468,0.4871370196342468,0.4418167173862457,0.4149106442928314,0.39483335614204407,0.37945884466171265,0.3687818944454193,0.35704949498176575,0.3485631048679352,0.3486655056476593]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('bd937d26', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 5126 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.268\n",
      "\tMean Loss (#loss): 0.253\n",
      "\tMean Accuracy (#acc): 90.67%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.363\n",
      "\tMean Loss (#loss): 0.349\n",
      "\tMean Accuracy (#acc): 84.80%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=bow;l2_regularization=1e-3;learning_rate=1e-4;normalization=none;train_steps=10000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62e0d8ed-31ed-49ba-8b6f-1518d3df8a8d",
   "metadata": {},
   "source": [
    "### Convolution Model (cnn)\n",
    "\n",
    "The function [`imdb.CnnModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_cnn.go) creates a 1D convolution model, with arbitrary number of convolutions. After the convolution, it behaves the same way as the Bag Of Words model.\n",
    "\n",
    "The core of the convolution model looks like this:\n",
    "\n",
    "```go\n",
    "\t// 1D Convolution: embed is [batch_size, content_len, embed_size].\n",
    "\tnumConvolutions := context.GetParamOr(ctx, \"cnn_num_layers\", 5)\n",
    "\tlogits := embed\n",
    "\tfor convIdx := range numConvolutions {\n",
    "\t\tctx := ctx.Inf(\"%03d_conv\", convIdx)\n",
    "\t\tresidual := logits\n",
    "\t\tif convIdx > 0 {\n",
    "\t\t\tlogits = NormalizeSequence(ctx, logits)\n",
    "\t\t}\n",
    "\t\tlogits = layers.Convolution(ctx, embed).KernelSize(7).Filters(embedSize).Strides(1).Done()\n",
    "\t\tlogits = activations.ApplyFromContext(ctx, logits)\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tlogits = layers.Dropout(ctx, logits, dropoutNode)\n",
    "\t\t}\n",
    "\t\tif residual.Shape().Equal(logits.Shape()) {\n",
    "\t\t\tlogits = Add(logits, residual)\n",
    "\t\t}\n",
    "\t}\n",
    "\n",
    "\t// Take the max over the content length, and put an FNN on top.\n",
    "\t// Shape transformation: [batch_size, content_len, embed_size] -> [batch_size, embed_size]\n",
    "\tlogits = ReduceMax(logits, 1)\n",
    "\tlogits = fnn.New(ctx, logits, 1).Done()\n",
    "\tlogits.AssertDims(batchSize, 1)\n",
    "```\n",
    "\n",
    "Notice how well it can overfit to the training data ... but it doesn't help the test results. To improve this one needs some careful regularization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f77a72a8-2872-4c56-9065-e245deb85169",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"xla\":\txla:cuda - PJRT \"cuda\" plugin (/usr/local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.54\n",
      "Model: cnn\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (10000 steps):    7% [\u001b[32m=\u001b[0m\u001b[32m>\u001b[0m......................................] (126 steps/s) [7s:1m13s]\u001b[0m [step=719] [loss+=0.680] [~loss+=0.713] [~loss=0.693] [~acc=51.66%]        "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (10000 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (144 steps/s)\u001b[0m [step=9999] [loss+=0.028] [~loss+=0.090] [~loss=0.073] [~acc=97.80%]         \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"d51353ad\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.543651819229126,0.5249682664871216,0.5130694508552551,0.4972773790359497,0.5884310603141785,0.7838099002838135,0.8495014905929565,0.8910372853279114,0.9059917330741882,0.9270147681236267,0.956047773361206,0.9672830104827881,0.9783621430397034,0.9780078530311584]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.5,0.5,0.5,0.5,0.6283199787139893,0.7862799763679504,0.8182799816131592,0.8670399785041809,0.8945199847221375,0.9375999569892883,0.9258399605751038,0.9429199695587158,0.9680399894714355,0.9726799726486206]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.5,0.5,0.5,0.5,0.5838800072669983,0.759440004825592,0.7814399600028992,0.8100000023841858,0.8148399591445923,0.8281999826431274,0.8062399625778198,0.8070399761199951,0.811199963092804,0.8134399652481079]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('d51353ad', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"32c51cc7\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.712389349937439,0.6873337030410767,0.7235093116760254,0.7100186944007874,0.6619800329208374,0.4017208516597748,0.436967670917511,0.3541628122329712,0.22079046070575714,0.14574477076530457,0.1963990032672882,0.04025989770889282,0.034754909574985504,0.027753634378314018]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.7376506328582764,0.7242375016212463,0.7133022546768188,0.7055723667144775,0.6822262406349182,0.4877735376358032,0.3824131488800049,0.3093629777431488,0.2661603093147278,0.20977123081684113,0.15184780955314636,0.12317004054784775,0.08607255667448044,0.08970385789871216]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6888469457626343,0.6917933225631714,0.6934535503387451,0.6937780380249023,0.6740733981132507,0.4764593243598938,0.36967933177948,0.29579806327819824,0.25186270475387573,0.19478043913841248,0.13624992966651917,0.1067974790930748,0.06911906599998474,0.0726577416062355]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.7371493577957153,0.7263209819793701,0.7114348411560059,0.7013384103775024,0.6545769572257996,0.4662630259990692,0.4279365539550781,0.34537646174430847,0.2918674647808075,0.19704583287239075,0.22682160139083862,0.18358522653579712,0.11781089752912521,0.10569989681243896]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.695792019367218,0.6995766758918762,0.694820761680603,0.6911514401435852,0.6463526487350464,0.45459097623825073,0.415060818195343,0.33169007301330566,0.2775152325630188,0.18197119235992432,0.21117205917835236,0.16719037294387817,0.10081145167350769,0.08860639482736588]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.7372134327888489,0.7265069484710693,0.7116773128509521,0.7021276354789734,0.677422821521759,0.5163085460662842,0.5154365301132202,0.4931779205799103,0.5206692218780518,0.52190101146698,0.6840299963951111,0.7530874013900757,0.8288416266441345,0.8202313780784607]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5199,6440,7929,9716,10000],\"y\":[0.6958551406860352,0.6997628211975098,0.6950631737709045,0.691940426826477,0.6691992878913879,0.504636287689209,0.5025612115859985,0.47949108481407166,0.5063179731369019,0.5068264603614807,0.668380856513977,0.736692488193512,0.8118414878845215,0.803136944770813]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('32c51cc7', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 10000] median train step: 5070 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.106\n",
      "\tMean Loss (#loss): 0.089\n",
      "\tMean Accuracy (#acc): 97.27%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.820\n",
      "\tMean Loss (#loss): 0.803\n",
      "\tMean Accuracy (#acc): 81.34%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=cnn;l2_regularization=1e-3;learning_rate=1e-4;normalization=layer;train_steps=10000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9adcb51-2190-4cfc-9224-07f7331bae41",
   "metadata": {},
   "source": [
    "### Transformer Model\n",
    "\n",
    "Finally a Transformer version of the model, as defined in the [\"Attention Is All You Need\"](https://arxiv.org/abs/1706.03762) famous paper. \n",
    "\n",
    "Notice it's not significantly better than our previous simple Bag-Of-Words model. Likely because there is not enough data for the transformer to make any difference. The success of transformers in large-language-models is in large part due to the training with huge amounts of unsupervised (or self-supervised) data, but that is beyond the scope of this small test.\n",
    "\n",
    "The code is in [`imdb.TransformerModelGraph`](https://github.com/gomlx/gomlx/blob/main/examples/imdb/model_transformer.go), and the core of it looks like this:\n",
    "\n",
    "```go\n",
    "    ...\n",
    "\t// Add the requested number of attention layers.\n",
    "\tnumAttLayers := context.GetParamOr(ctx, \"transformer_num_att_layers\", 1)\n",
    "\tnumAttHeads := context.GetParamOr(ctx, \"transformer_num_att_heads\", 2)\n",
    "\tattKeySize := context.GetParamOr(ctx, \"transformer_att_key_size\", 8)\n",
    "\tfor layerNum := range numAttLayers {\n",
    "\t\t// Each layer in its own scope.\n",
    "\t\tctx := ctx.Inf(\"%03d_attention_layer\", layerNum)\n",
    "\t\tresidual := embed\n",
    "\t\tembed = layers.MultiHeadAttention(ctx.In(\"000_attention\"), embed, embed, embed, numAttHeads, attKeySize).\n",
    "\t\t\tSetKeyMask(mask).SetQueryMask(mask).\n",
    "\t\t\tSetOutputDim(embedSize).\n",
    "\t\t\tSetValueHeadDim(embedSize).Done()\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tembed = layers.Dropout(ctx.In(\"001_dropout\"), embed, dropoutNode)\n",
    "\t\t}\n",
    "\t\tembed = NormalizeSequence(ctx.In(\"002_normalization\"), embed)\n",
    "\t\tattentionOutput := embed\n",
    "\n",
    "\t\t// Transformers recipe: 2 dense layers after attention.\n",
    "\t\tembed = fnn.New(ctx.In(\"003_fnn\"), embed, embedSize).NumHiddenLayers(1, embedSize).Done()\n",
    "\t\tif dropoutNode != nil {\n",
    "\t\t\tembed = layers.Dropout(ctx.In(\"004_dropout\"), embed, dropoutNode)\n",
    "\t\t}\n",
    "\t\tembed = Add(embed, attentionOutput)\n",
    "\t\tembed = NormalizeSequence(ctx.In(\"005_normalization\"), embed)\n",
    "\n",
    "\t\t// Residual connection:\n",
    "\t\tif layerNum > 0 {\n",
    "\t\t\tembed = Add(residual, embed)\n",
    "\t\t}\n",
    "\t}\n",
    "    ...\n",
    "```\n",
    "\n",
    "With only 5000 steps we got ~87% on the test data -- and significant overfitting as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "20ac0032-de61-4573-88db-fbac6730ac9f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "> Loading previously generated preprocessed binary file.\n",
      "Loaded data from \"aclImdb.bin\": 100000 examples, 141088 unique tokens, 23727054 tokens in total.\n",
      "Backend \"xla\":\txla:cuda - PJRT \"cuda\" plugin (/usr/local/lib/gomlx/pjrt/pjrt_c_api_cuda_plugin.so) v0.54\n",
      "Model: transformer\n"
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (5000 steps):   14% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m>\u001b[0m...................................] (64 steps/s) [15s:1m7s]\u001b[0m [step=724] [loss+=0.693] [~loss+=0.693] [~loss=0.692] [~acc=51.78%]        "
     ]
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training (5000 steps):  100% [\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m\u001b[32m=\u001b[0m] (58 steps/s)\u001b[0m [step=4999] [loss+=0.099] [~loss+=0.222] [~loss=0.184] [~acc=93.65%]          \n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: accuracy</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"09dc8238\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.4819435179233551,0.5219549536705017,0.5171759128570557,0.536597728729248,0.6800543069839478,0.7317606806755066,0.8544602990150452,0.8949645161628723,0.9185358285903931,0.9364860653877258]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.5,0.5,0.5,0.5162000060081482,0.7828399538993835,0.8120799660682678,0.8785600066184998,0.9002400040626526,0.9287599921226501,0.942039966583252]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Accuracy\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.5,0.5,0.5,0.5091999769210815,0.7661199569702148,0.795799970626831,0.8428799510002136,0.8559199571609497,0.8689199686050415,0.8721599578857422]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"accuracy\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('09dc8238', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<p><b>Metric: loss</b></p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div id=\"425690ef\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<script charset=\"UTF-8\">\n",
       "(() => {\n",
       "\tconst src=\"https://cdn.plot.ly/plotly-2.29.1.min.js\";\n",
       "\tvar runJSFn = function(module) {\n",
       "\t\t\n",
       "\tif (!module) {\n",
       "\t\tmodule = window.Plotly;\n",
       "\t}\n",
       "\tlet data = JSON.parse('{\"data\":[{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Batch Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6954239010810852,0.6941613554954529,0.6877517700195312,0.6900813579559326,0.6869860887527466,0.6456635594367981,0.22263813018798828,0.25155526399612427,0.19309937953948975,0.09931112825870514]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6984889507293701,0.6946689486503601,0.6926056742668152,0.6912198662757874,0.6855496764183044,0.6573953628540039,0.3806374967098236,0.2924249768257141,0.24827708303928375,0.22155345976352692]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Train: Moving Average Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6938860416412354,0.692780613899231,0.6918573975563049,0.6907868385314941,0.684824526309967,0.6539149880409241,0.35097259283065796,0.25855034589767456,0.21258358657360077,0.18435341119766235]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6961564421653748,0.6939043402671814,0.6927403807640076,0.6902917623519897,0.6826539635658264,0.6416569352149963,0.3275136947631836,0.28380224108695984,0.22890794277191162,0.19877220690250397]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on train-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.693016529083252,0.6927384734153748,0.6921783685684204,0.6898778080940247,0.6817370057106018,0.6370587944984436,0.29659613966941833,0.24969105422496796,0.19300776720046997,0.16165150701999664]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss+Regularization\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6961652040481567,0.693953812122345,0.6929237842559814,0.6906323432922363,0.683509349822998,0.6455513834953308,0.3863299489021301,0.3622003495693207,0.3449283540248871,0.3459925949573517]},{\"type\":\"scatter\",\"line\":{\"shape\":\"linear\"},\"mode\":\"lines+markers\",\"name\":\"Eval on test-eval: Mean Loss\",\"x\":[200,440,728,1074,1489,1987,2585,3303,4165,5000],\"y\":[0.6930254697799683,0.6927879452705383,0.6923614740371704,0.6902179718017578,0.6825925707817078,0.6409537196159363,0.35541266202926636,0.32808923721313477,0.3090282678604126,0.30887189507484436]}],\"layout\":{\"legend\":{},\"title\":{\"text\":\"loss\"},\"xaxis\":{\"showgrid\":true,\"type\":\"log\"},\"yaxis\":{\"showgrid\":true,\"type\":\"log\"}}}');\n",
       "\tmodule.newPlot('425690ef', data);\n",
       "\n",
       "\t}\n",
       "\t\n",
       "    if (typeof requirejs === \"function\") {\n",
       "        // Use RequireJS to load module.\n",
       "\t\tlet srcWithoutExtension = src.substring(0, src.lastIndexOf(\".js\"));\n",
       "        requirejs.config({\n",
       "            paths: {\n",
       "                'plotly': srcWithoutExtension\n",
       "            }\n",
       "        });\n",
       "        require(['plotly'], function(plotly) {\n",
       "            runJSFn(plotly)\n",
       "        });\n",
       "        return\n",
       "    }\n",
       "\n",
       "\tvar currentScripts = document.head.getElementsByTagName(\"script\");\n",
       "\tfor (const idx in currentScripts) {\n",
       "\t\tlet script = currentScripts[idx];\n",
       "\t\tif (script.src == src) {\n",
       "\t\t\trunJSFn(null);\n",
       "\t\t\treturn;\n",
       "\t\t}\n",
       "\t}\n",
       "\n",
       "\tvar script = document.createElement(\"script\");\n",
       "\n",
       "\tscript.charset = \"utf-8\";\n",
       "\t\n",
       "\tscript.src = src;\n",
       "\tscript.onload = script.onreadystatechange = function () { runJSFn(null); };\n",
       "\tdocument.head.appendChild(script);\t\n",
       "})();\n",
       "</script>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t[Step 5000] median train step: 15766 microseconds\n",
      "\n",
      "Results on train-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.199\n",
      "\tMean Loss (#loss): 0.162\n",
      "\tMean Accuracy (#acc): 94.20%\n",
      "Results on test-eval:\n",
      "\tMean Loss+Regularization (#loss+): 0.346\n",
      "\tMean Loss (#loss): 0.309\n",
      "\tMean Accuracy (#acc): 87.22%\n"
     ]
    }
   ],
   "source": [
    "%% --set=\"model=transformer;normalization=none;activation=swish;l2_regularization=1e-3;cnn_dropout_rate=0.5;fnn_dropout_rate=0.3;learning_rate=1e-4;train_steps=5000\"\n",
    "ctx, paramsSet := ContextFromSettings()\n",
    "imdb.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet, *flagEval, *flagVerbosity)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.22.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
