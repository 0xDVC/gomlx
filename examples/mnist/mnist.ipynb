{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST\n",
    "\n",
    "MNIST is a simple computer vision dataset that consists of images of handwritten digits.\n",
    "\n",
    "Some examples:\n",
    "\n",
    "![MNIST digits sample](https://github.com/user-attachments/assets/996c11e0-47f9-4b21-8e23-3867b8942e64)\n",
    "\n",
    "It also includes labels for each image, which we use to train our example models.\n",
    "\n",
    "## The `mnist` library\n",
    "\n",
    "This package includes the following functionality:\n",
    "\n",
    "  - Download the dataset from [storage.googleapis.com/cvdf-datasets/mnist](https://storage.googleapis.com/cvdf-datasets/mnist),\n",
    "  - Create a `Dataset` object to iterate over it, use for training and evaluation.\n",
    "  - A linear and a CNN model demo.\n",
    "  - A command-line demo (in the `demo` sub-directory).\n",
    "\n",
    "This notebook serves as documentation and example for the [github.com/gomlx/gomlx/examples/mnist](https://github.com/gomlx/gomlx/examples/mnist) library, and the demo code in one piece can be seen in [.../examples/mnist/demo/](https://github.com/gomlx/gomlx/tree/main/examples/mnist/demo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Environment Set Up\n",
    "\n",
    "Let's set up `go.mod` to use the local copy of GoMLX, so it can be developed jointly the dataset code with the model. That's often how data pre-processing and model code is developed together with experimentation.\n",
    "\n",
    "If you are not changing code, feel free to simply skip this cell. Or if you used a different directory for you projects, change it below.\n",
    "\n",
    "Notice the directory `${HOME}/Projects/gomlx` is where the GoMLX code is copied by default in [its Docker](https://hub.docker.com/repository/docker/janpfeifer/gomlx_jupyterlab/general)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- Added replace rule for module \"github.com/gomlx/gomlx\" to local directory \"/home/rener/dev/gomlx\".\n"
     ]
    }
   ],
   "source": [
    "!*rm -f go.work && go work init && go work use . \"${HOME}/dev/gomlx\"\n",
    "%goworkfix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "### Downloading data files\n",
    "\n",
    "To download to the local directory, simply do the following. Notice if it's already downloaded in the given `--data` directory, it returns immediately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import (\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/ml/data\"\n",
    "    \"github.com/janpfeifer/must\"\n",
    ")\n",
    "\n",
    "var flagDataDir = flag.String(\"data\", \"~/work/mnist\", \"Directory to cache downloaded and generated dataset files.\")\n",
    "\n",
    "func AssertDownloaded() {\n",
    "    *flagDataDir = data.ReplaceTildeInDir(*flagDataDir)\n",
    "    if !data.FileExists(*flagDataDir) {\n",
    "        must.M(os.MkdirAll(*flagDataDir, 0777))\n",
    "    }\n",
    "\n",
    "   must.M(mnist.Download(*flagDataDir))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total 12M\n",
      "-rw-r--r-- 1 rener rener 1.6M Feb 13 23:43 t10k-images-idx3-ubyte.gz\n",
      "-rw-r--r-- 1 rener rener 4.5K Feb 13 23:43 t10k-labels-idx1-ubyte.gz\n",
      "-rw-r--r-- 1 rener rener 9.5M Feb 13 23:43 train-images-idx3-ubyte.gz\n",
      "-rw-r--r-- 1 rener rener  29K Feb 13 23:43 train-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "!ls -lh ~/work/mnist/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample some images\n",
    "The `mnist.NewDataset` creates a `data.InMemoryDataset` that can be used both for training, evaluation, or just to sample a few examples, which we do below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Samples MNIST</p>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<table><tr>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABzklEQVR4nNyVMcviMBiADz2VqFsbdRTBgkoR3PwBLtbFWbq5uYjoH3ATBNFB0OlEHF38Aw4ZBaU4iJOOFamDBF1McmCglA+xd19798H3THlj8vj2zdvU8+Mf8C2lxWKRMUYI6XQ6Pp/PhT8vl8sYY0LI44ksyy5IN5vN4/FwU1qtVjHGphQhBABwZMxkMrfbjSfIpe12+/2Wn+9/9nq9iqIEAgEeejweSilCyJHU7/eXSiXGGA8ppeb4DTYtdb/fu92udQZjbBiGrdcGAIAsy/P5nNd0vV47zZQnu91uY7EYD1erldM0OZIknU4nQsj1ek2n0+5IK5UKbylN0/5k/evTFwRBVVVBEBBCEMJer8fnp9Pp51Or1+vWbjeZzWaJROIzxkgkstvtXkoJIZfLZTAYNJvNUCj0F9JsNkueRKPR5XJJLPCrzxrqul6r1T7chC9aCkLInoiieDwe+Xi/32uaxt8oE0qpKIr9fr/RaFgNLw4qGAzywWKxiMfjjDHDMBRFORwOhUIBQqiqaj6fD4fD5pZUKmXz+ACA8XhsFvF8PrdarQ9rksnkcDicTCa/nuRyOfuySpKk6zqXjkYj+w3/ga/+mn5H6e8AAAD//ypsSsmQzB9KAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAB6UlEQVR4nOyVr6siURTH7503GLwIlrFYTCZFLWaT3TBhwvwH/sKixWgSDYLFIAgKChYxaLCoRQSzigjiBJVhBHHAET264bKzb5flvafjLizsJ10unM/9Hg4zh0F/gP/SvyXFGDudzlQqdTweb9+53+/T6TSTyTz5FM/z8A5Jklqt1nq9BoDT6ZTL5Z6RJhIJAJjP54IgOBwOjuMQQhzHxWIxABgMBh+X/779/X6PEGJZdjwer1YrWZYRQrIsVyoVVVUVRXkmKcuyy+USABqNxvt7URQVRbHZbM9IEUJWq7XX610ul2w2+/b2Ri8FQdhut+RnMMaPqSVJAoB2u22xWAghgiBomqYP8HA4TCYTlmUfk4bDYVpfKBTq9bqu63Q60WjU5XI9pqNgjMvlsu7SNK3ZbHIc93C6X/D5fLpUFMWvlHz+mfI8r5/dbrehgBSMca1WAwBZlmn7wWDQqJQQQhu32+39fh8AhsPhy6SRSMTv9+92u/P5HI/HDUkxxsVikbZvNpvz+TwAjEYjk8lkyKtPP5lMiqJIz16v94OSz6c/m82q1SpCKJ1OE0JUVTWU8cfLDLNYLADger3SpKVSyVBShNDtdguFQpvNRv93MMyL9pDH4+l2uzRpIBB4jfTr/Dsr+lsAAAD//3+5LEbYr36zAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([8])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABhUlEQVR4nOyVsarCMBSGQ+hkFy2KmwgVC4KDk7vgC7g5KW5OTj6DGXyGTplc3Bx0kryCgkocBYWAQbfAqRcMiKi17b2Vu/hNoSf5zp+0oRh9gK/0K/WpYVwsFskVIYR35XK56MFqtSKEWJYVrWG73YYgBoPB80LjTcx6va7HUsrxeDyZTO4nEEJs244Ws9Vq3eI0m82HaqVSkVL6JfVlu90CwPF4bDQapmnel1Kp1HQ61f0cx4kgPZ/PALBYLJ5LnU5HGymlGL941b5nqpQyDIMx9vDcsqxer6fHs9nM87wISV+CMXZdV8ccDofJZPKvRoRQPp/Xxvl8nk6nYzAihJbLJQBwzjOZTDxG27aVUgAwGo1CLSiXy+8nFAoFzjkAnE6narUaSlqr1d5PuN2Ffr8fyhhIIpHQpymEePlh/gbGmI4ZduOBOI5zOBwAYL/fG4bvZYmAaZqUUgDY7XbdbjcGI0KoVCrpjbuuG37VR34nAWSz2c1ms16vc7ncP7S/5ycAAP//TbzwnBdu+2kAAAAASUVORK5CYII=\"><figcaption style=\"text-align: center;\">([7])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACK0lEQVR4nOyVy2viUBTGL9NpSwuhkFJoodAWmlIodFG6TUgh7SoU8YGo+NroSvwnBJeCW0FQXAiCK9GFiIhmoSAug4Ki+NwFMaDmgbO4cJFhHOM4XQzMtzo5ud8v300Oud/AF+g/9B+Bft9pNYZh7+/vLy8vl5eXbrcb9W9vb/v9/m5Pvri4uLq60uv1qqoqv1K5XD46OtqB6Pf7BUGAZgidz+fBYNDlcvE8D/uhUGjdsnH7p6enDMPYbLbr62sMw2BzsVg4nU5RFJvNpsfjwXEcAJBMJmOx2PZ0Dw8PkUhkfYMcxy2XS0mSDAYDSZKFQgH2J5OJyWTaTjw/Px+NRghXKpVYliUIQhRFVVW73S66NR6PKYraTjw8PIxGoygFy7InJycAAJ/Ph94pUiaT2U4EAHx8fCCPxWJBfYZharWaRujPH+r19RUWXq83nU7D2uFwnJ2d3d3dra+sVqt2u11T0kAgAFN0Op1GozGdTnO5nCzL6yOlKMpwOHx6etJEBADQNM1xnLpBq9UKcnU6nVYiFEVR2WxWEITBmiRJQknD4fBuRKTn52dUf35+zmYzCI3H4wRB/CEU6fHxEc3mYDAwm837EgEA9XodzRBN01osv/v14ThutVrv7+/hZT6fb7fb+2YkSRJlTCQSBwcH+xLf3t6KxSIk8jx/c3Oj3bvxOJFlmSRJWFcqlV6vt29MAIDRaGy1WoqipFKp4+Pjv0DcU19ymv4IAAD//0Son78ABw7NAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([9])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAByElEQVR4nNyVz8spURjHH7eLUGOjLJUsZmFjOSVLFpL8BdSxkp0s7KdslVJWs7awoCjZ2SkKG2OhWElCpqZGnuPcek+p632vH925dXs/u3PmzOd8T53nOT/gH/CdpFartVgsyrJsGAZjjFKqKMrjX34+cOVyOb/fHwgEYrEYn7xer4wxSZLeTw/g9XrL5TL+zm63o5QioqqqbxtFUVwul1x0OBxGH6TT6WAw+KL0i+MnEgmfz6eqaq1WGw6H4/H47Vyfsdls4XDY4/F8/sSTdjodE7bhEEK4NJPJmCZdrVaU0l6vJwiCOUZCyOVyoZTm8/mni1+tKKfTabFYdF2v1+t/nfADSZI0TaOUNptNc4wAsFgsEPF0OplmjEajx+MREQuFgjnGUCi03+8RcbPZOBwOc6SKovB6fSvmH7sUAKRSqWQyCQDdbrdard7mXS5XJBK5DQeDga7rr0qz2Sy/55PJhNtLpRJjzG63i6J4W9ZoNAghhmE8yS8IQqvV0jTtrvvxMr1jPp+73e7nSWVZjsfjjzdut9vr9RoAKpXK3W37Wjqbze6G2+12Op0iYr/fH41GAHA+nxHxyZFN5Ds90f+L9FcAAAD//08ME1mBZRmYAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABBklEQVR4nOyVMWqEUBCG52XzBAXBQrQVrSzF3sLCO3gCz2Fv4S0sbLzAO4FeQbG1FWyCxsA+IqR6s5sJ2+Sr/mLmm19EfIM/4F+KZRiGtm0pj9u2PU3Ttm1RFCmHsU3f7+i6bpommfTjDgD4vk8mDYJA6rIsI5MCAGMMOfmA9DxPeikelJQxluc58WVN0z6/qeuaXpokiXIe9fhFUciwLMs4jr8uCeA4Tt/3smbXdZgVddMwDOM4llkIQSP1PO/K8zxjpGqaprneEuccs6Joyjl3XVdmIcRxHAQ1Lcu6aqZpitx64DNd1/XZbj+53W5VVe37XpalYRg00ud49d/0xdKvAAAA//+9OmZ0PsqwdAAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([1])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABQUlEQVR4nOTVoY7CQBAG4LnjFAlBLA7W8gCA4AkQOCQKgeAtwGBROBKeAccToEgqarZJq1b0AZptsmZm95LWXS6FNlNxuV93vsy0091PaCH/HO00qJFSPp/PwWDweDycczyNnE4nLDIajXhEAEjTlB8lIkRUSvX7fR5xv99774loPp/ziMfj0RhDREopIQSDKISIoggR8zxfrVYMIgBcr9fy+9xuNx5RSklFsiybTqfVD3+9iW63W+89AFwulyAIGNpcr9flGiHibDZjEMfjsda6RA+HQ6fT5M/+mfP5TETOOWvtZDJhEHu9XhiGiGit3e12DCIAbDab8lVqrd+venGeLpfLBq28WKmPIgBwv98b6L9ECKG1LsevVVg1frfbHQ6HABDHcS20anxjTJIk3vvFYlELbSV/54puBf0OAAD//2hLpMiDLXAUAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([1])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABqElEQVR4nNyUv4rqQBSHT/6IiE2CGhJQG7EQ9AHUVixsJVXIS6iPYCHYasDWRuyChdgHbiHYWGhh6VRqI4gghMktZGWMmWDc3SL7lZM53/nlJDMs/AJ/QBqPxw3DwASn00mWZVEUP+/W6XTsZzDGtm1blpXNZv1rOdqDSqVSq9XIFYZhHMfJZDLFYvFwOORyuev1erlcAiRtNBrr9fo1KYmmacGS7na7/X6PEPr3RbVadRyH3HO73Var1fl8DhDWRbvd7vf7rrDT6VRRlM+lACCKoqZpw+GQ9JZKpW9J7+i67i8Nz4nigxZEo1FBEDiOe/wJiUSCZVmM8WMPQyuWJMnzs5bL5cFg4FpUFOV4PPplSSaT9Xp9NBp5HlNPVFWl6mKxmK7rvV7Ps9JHOplMSM/T68uyjBCitXQNDgDm8/lmswGAbrdLvQQMwyD7m6bZarW2261nUtM0C4WC3xzvuMqWy+V4PEYIvUpns9lbRgBQVZU2NVK6WCzy+fxbRgCIRCLNZtNfallWOp1+13iH53laXkmSUqmUIAjBjD9FeC6U8Ej/BwAA//+db9W84gMxHAAAAABJRU5ErkJggg==\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAABlUlEQVR4nNyVL4sCURTFHyr+H5RJgsUilkmDRSwGweAnMGmxKgg2xTjZpJgMotg02EQwiEmTiNoFi8rAQ3nh3llwloVdWEdm3sLiaXM498eZucN7NvIHemNotVpFxNlsxq1CJBI5n88AUCgUuEG32y0AlEolp9PJh5jP5xFRURRuREJIp9NhjEmSxI0oSRJjrF6vcyMSQmq12nw+fzH80i/l8XhyudxisbBW7LvS6TQAyLL8Yt5umPB6ve122+fziaIoy/Jms7ndblZrRqNRfIhSqmkapTSTybhcricjxt80m81qD00mk1QqNRwOR6NRpVKx1LTVah2Px0QiIYqi7vT7fVVVBUEw3zQWi51Op+VyeblcdOdwOPj9frv9130YQAOBQDKZ/GGGQqHdbmd+XcFgEBHX6/WXE4/Hr9druVx+MmX8+vqWPtM2W7FYdLvd+/3eZE1CiCAIqqquViv9UVEUAGg0GuaJuprN5v1+H4/Hg8EAEbvdLoejLxwOT6dTeKjX6zkcDqtEc/oft+l7QT8CAAD//zG/qs3n8n/uAAAAAElFTkSuQmCC\"><figcaption style=\"text-align: center;\">([6])</figcaption></figure></td>\n",
       "<td><figure style=\"padding:4px;text-align: center;\"><img width=\"56\" height=\"56\" src=\"data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAACRUlEQVR4nOyVv0vrUBSA02dQCGaVRAQ30UkkS50EHePgEBEJmkFFHRy6OcUsbmZwMPkXzJoMIoIuHYSQCC6KTgaD2CFLSkvLObkPGuwrvqS/wOXxvuly77lfTs7hJL+oH+C/NBdd1+/u7mzbdl2XEGLb9sHBAU3Twz9tb28PEeGL9lrTtCGNKysrtVrN9/2tra3iFxcXF6lXVdVhpNfX1wDAsmzn5tjY2P7+PgA0m01RFAczHh8fI+LZ2VnmqWmaSZK8v79PT0/nGTIatbCwQAjheT7zwuHhISGE47idnZ0BpPf391EUjY+P5915fX2lKGp5eZlhmLyYDCYmJkZGRvJO5+bm0o5NTU0NIO0Oy7IPDw9d6j7ARE1OTqaLOI5fXl5Ii8zIbuPBMIwoihsbGzzPFwoFjuM+Pj583z86Ouo/lT/MzMyUSqUwDP+eKAAIgiCOYwCYnZ3t16goShiGiBgEgWEYpRYURa2urhqGEUVRkiSI+Pz83G+jFEV5e3v7/Pw8Pz/PDFhaWmpn/fT01C50N3RdB4DLy8u8AMMwELHcAgAeHx975yvLMgB4nvdt8FNUVW00GogoSdL6+npa60qlsru728NrWRYiuq7b+Wo0TWuahi0EQUg3BUFIq4+Isix3kxaLxdvbWwCoVqvb29uKoliW5ThOWkfTNDuDGYY5PT2VJGl+fr5HsouLi57nfftIl8vltbW10dHRHpcpqpB3wLLsyckJIWRzc9NxnKurq5ubm3q93tP4U/wbv+ih+R0AAP//61Ri370ayqkAAAAASUVORK5CYII=\"><figcaption style=\"text-align: center;\">([2])</figcaption></figure></td>\n",
       "</tr></table>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import (\n",
    "    \"fmt\"\n",
    "    \"strings\"\n",
    "\t\"strconv\"\n",
    "    \"github.com/gomlx/gopjrt/dtypes\"\n",
    "    \"github.com/gomlx/gomlx/backends\"\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/types/shapes\"\n",
    "    \"github.com/gomlx/gomlx/types/tensors/images\"\n",
    "    \"github.com/janpfeifer/gonb/gonbui\"\n",
    "\n",
    "    _ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    // Model DType, used everywhere.\n",
    "    DType = dtypes.Float32\n",
    ")\n",
    "\n",
    "// sampleToNotebook generates a sample of MNIST in a GoNB Jupyter Notebook.\n",
    "func sampleToNotebook() {\n",
    "    // Load data into tensors.\n",
    "    backend := backends.New()\n",
    "    if ds, err := mnist.NewDataset(backend, \"Samples MNIST\", *flagDataDir, \"train\", DType); err != nil {\n",
    "        fmt.Printf(\"mnist.NewDataset: %v\", err)\n",
    "    } else {\n",
    "        ds.Shuffle()\n",
    "        sampleImages(ds, 10)\n",
    "    }\n",
    "   \n",
    "}\n",
    "\n",
    "// sampleTable generates and outputs one html table of samples, sampling rows x cols from the images/labels provided.\n",
    "func sampleImages(ds train.Dataset, numImages int) {\n",
    "    gonbui.DisplayHTML(fmt.Sprintf(\"<p>%s</p>\\n\", ds.Name()))\n",
    "    \n",
    "    parts := make([]string, 0, numImages+5) // Leave last part empty.\n",
    "    parts = append(parts, \"<table><tr>\")\n",
    "    for ii := 0; ii < numImages; ii++ {\n",
    "        _, inputs, labels := must.M3(ds.Yield())\n",
    "        imgTensor := inputs[0]\n",
    "        img := images.ToImage().Single(imgTensor)\n",
    "        label := labels[0].Value().([]int8)\n",
    "    \n",
    "        imgSrc := must.M1(gonbui.EmbedImageAsPNGSrc(img))\n",
    "        size := imgTensor.Shape().Dimensions[0]\n",
    "        parts = append(\n",
    "            parts, \n",
    "            fmt.Sprintf(`<td><figure style=\"padding:4px;text-align: center;\"><img width=\"%d\" height=\"%d\" src=\"%s\">` + \n",
    "                        `<figcaption style=\"text-align: center;\">(%d)</figcaption></figure></td>`, \n",
    "                        size*2, size*2, imgSrc, label),\n",
    "        )\n",
    "    }\n",
    "    parts = append(parts, \"</tr></table>\", \"\")\n",
    "    gonbui.DisplayHTML(strings.Join(parts, \"\\n\"))\n",
    "}\n",
    "\n",
    "%%\n",
    "AssertDownloaded()\n",
    "sampleToNotebook()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training on MNIST\n",
    "\n",
    "### Models Support\n",
    "\n",
    "1. `flagModel` defines the model type, out of `validModels` options.\n",
    "1. `createDefaultContext` creates a context and set the default values for the MNIST models. \n",
    "1. `contextFromSettings` uses `createDefaultContext` and incorporate changes passed by the `-set` flag."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model types: [\"linear\" \"cnn\"]\n",
      "Parameters set (-set): [\"batch_size\" \"model\" \"train_steps\"]\n",
      "\t\"/activation\": (string) relu\n",
      "\t\"/adam_dtype\": (string) \n",
      "\t\"/adam_epsilon\": (float64) 1e-07\n",
      "\t\"/batch_size\": (int) 17\n",
      "\t\"/cnn_dropout_rate\": (float64) 0.5\n",
      "\t\"/cnn_normalization\": (string) layer\n",
      "\t\"/cosine_schedule_steps\": (int) 0\n",
      "\t\"/dropout_rate\": (float64) 0.5\n",
      "\t\"/eval_batch_size\": (int) 1000\n",
      "\t\"/l1_regularization\": (float64) 0\n",
      "\t\"/l2_regularization\": (float64) 0\n",
      "\t\"/learning_rate\": (float64) 0.0001\n",
      "\t\"/loss\": (string) cross-entropy\n",
      "\t\"/model\": (string) 'cnn'\n",
      "\t\"/nan_logger\": (bool) false\n",
      "\t\"/num_checkpoints\": (int) 3\n",
      "\t\"/optimizer\": (string) adamw\n",
      "\t\"/plots\": (bool) false\n",
      "\t\"/train_steps\": (int) 10\n",
      "Parameters set (-set): [\"batch_size\" \"model\" \"train_steps\"]\n",
      "\t\"/activation\": (string) relu\n",
      "\t\"/adam_dtype\": (string) \n",
      "\t\"/adam_epsilon\": (float64) 1e-07\n",
      "\t\"/batch_size\": (int) 17\n",
      "\t\"/cnn_dropout_rate\": (float64) 0.5\n",
      "\t\"/cnn_normalization\": (string) layer\n",
      "\t\"/cosine_schedule_steps\": (int) 0\n",
      "\t\"/dropout_rate\": (float64) 0.5\n",
      "\t\"/eval_batch_size\": (int) 1000\n",
      "\t\"/l1_regularization\": (float64) 0\n",
      "\t\"/l2_regularization\": (float64) 0\n",
      "\t\"/learning_rate\": (float64) 0.0001\n",
      "\t\"/loss\": (string) cross-entropy\n",
      "\t\"/model\": (string) 'cnn'\n",
      "\t\"/nan_logger\": (bool) false\n",
      "\t\"/num_checkpoints\": (int) 3\n",
      "\t\"/optimizer\": (string) adamw\n",
      "\t\"/plots\": (bool) false\n",
      "\t\"/train_steps\": (int) 10\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"flags\"\n",
    "    \n",
    "    \"github.com/gomlx/gomlx/ml/layers\"\n",
    "    \"github.com/gomlx/gomlx/ui/commandline\"\n",
    "    \"github.com/gomlx/gomlx/ml/train/optimizers\"\n",
    "    \"github.com/gomlx/gomlx/examples/mnist\"\n",
    "    \"github.com/gomlx/gomlx/ml/context\"\n",
    ")\n",
    "\n",
    "var (\n",
    "    // ValidModels is the list of model types supported.\n",
    "    ValidModels = []string{\"linear\", \"cnn\"}\n",
    "\tflagEval      = flag.Bool(\"eval\", true, \"Whether to evaluate the model on the validation data in the end.\")\n",
    ")\n",
    "\n",
    "// settings is bound to a \"-set\" flag to be used to set context hyperparameters.\n",
    "var settings = commandline.CreateContextSettingsFlag(CreateDefaultContext(), \"set\")\n",
    "\n",
    "// createDefaultContext sets the context with default hyperparameters\n",
    "func CreateDefaultContext() *context.Context {\n",
    "\tctx := context.New()\n",
    "\tctx.RngStateReset()\n",
    "\tctx.SetParams(map[string]any{\n",
    "\t\t// Model type to use\n",
    "\t\t\"model\":           \"linear\",\n",
    "\t\t\"num_checkpoints\": 3,\n",
    "\t\t\"train_steps\":     4000,\n",
    "\n",
    "\t\t// batch_size for training.\n",
    "\t\t\"batch_size\": 600,\n",
    "\n",
    "\t\t// eval_batch_size can be larger than training, it's more efficient.\n",
    "\t\t\"eval_batch_size\": 1000,\n",
    "\n",
    "\t\t// Debug parameters.\n",
    "\t\t\"nan_logger\": false, // Trigger nan error as soon as it happens -- expensive, but helps debugging.\n",
    "\n",
    "\t\t// \"plots\" trigger generating intermediary eval data for plotting, and if running in GoNB, to actually\n",
    "\t\t// draw the plot with Plotly.\n",
    "\t\t//\n",
    "\t\t// From the command-line, an easy way to monitor the metrics being generated during the training of a model\n",
    "\t\t// is using the gomlx_checkpoints tool:\n",
    "\t\t//\n",
    "\t\t//\t$ gomlx_checkpoints --metrics --metrics_labels --metrics_types=accuracy  --metrics_names='E(Tra)/#loss,E(Val)/#loss' --loop=3s \"<checkpoint_path>\"\n",
    "\t\tplotly.ParamPlots: false,\n",
    "\n",
    "\t\toptimizers.ParamOptimizer:       \"adamw\",\n",
    "\t\toptimizers.ParamLearningRate:    1e-4,\n",
    "\t\toptimizers.ParamAdamEpsilon:     1e-7,\n",
    "\t\toptimizers.ParamAdamDType:       \"\",\n",
    "\t\tcosineschedule.ParamPeriodSteps: 0,\n",
    "\t\tactivations.ParamActivation:     \"relu\",\n",
    "\t\tlayers.ParamDropoutRate:         0.5,\n",
    "\t\tregularizers.ParamL2:            0.0,\n",
    "\t\tregularizers.ParamL1:            0.0,\n",
    "\n",
    "\t\t// CNN\n",
    "\t\t\"cnn_dropout_rate\":  0.5,\n",
    "\t\t\"cnn_normalization\": \"layer\", // \"layer\" or \"batch\".\n",
    "\t})\n",
    "\treturn ctx\n",
    "}\n",
    "\n",
    "// ContextFromSettings is the default context (createDefaultContext) changed by -set flag.\n",
    "func ContextFromSettings() (ctx *context.Context, paramsSet []string) {\n",
    "    ctx = mnist.CreateDefaultContext()\n",
    "    paramsSet = must.M1(commandline.ParseContextSettings(ctx, *settings))\n",
    "    return\n",
    "}\n",
    "\n",
    "// Let's test that we can set hyperparameters by setting it in the \"-set\" flag:\n",
    "%% -set=\"batch_size=17;model='cnn';train_steps=10\"\n",
    "fmt.Printf(\"Model types: %q\\n\", ValidModels)\n",
    "ctx, parametersSet := ContextFromSettings()\n",
    "fmt.Printf(\"Parameters set (-set): %q\\n\", parametersSet)\n",
    "fmt.Println(commandline.SprintContextSettings(ctx))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear model\n",
    "\n",
    "A linear model can easily get to ~92% accuracy (a random model would do 10%) with 4000 steps.\n",
    "\n",
    "Later we are going to define a CNN model to compare, and we just set a placeholder model here for now.\n",
    "\n",
    "> **Note**: \n",
    ">\n",
    "> * The code is here just to exemplify. We are actually using the same code from the [`mnist`](https://github.com/gomlx/gomlx/tree/main/examples/mnist) package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=10: (Float32)[10 10]\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "\t. \"github.com/gomlx/gomlx/graph\"\n",
    "\t\"github.com/gomlx/gomlx/ml/context\"\n",
    "\t\"github.com/gomlx/gomlx/ml/layers\"\n",
    ")\n",
    "\n",
    "var _ = NewGraph  // Make sure the graph package is in use.\n",
    "\n",
    "// LinearModelGraph builds a simple  model logistic model\n",
    "// It returns the logit, not the predictions, which works with most losses with shape `[batch_size, NumClasses]`.\n",
    "// inputs: only one tensor, with shape `[batch_size, width, height, depth]`.\n",
    "func LinearModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tctx = ctx.In(\"model\") // Create the model by default under the \"/model\" scope.\n",
    "\tbatchSize := inputs[0].Shape().Dimensions[0]\n",
    "\tembeddings := Reshape(inputs[0], batchSize, -1)\n",
    "\tlogits := layers.DenseWithBias(ctx, embeddings, mnist.NumClasses)\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "\n",
    "%% -set=\"batch_size=10\"\n",
    "// Let's test that the logits are coming out with the right shape: we want [batch_size, 10], since there are 10 classes.\n",
    "AssertDownloaded()\n",
    "ctx, _ := ContextFromSettings()\n",
    "g := NewGraph(backends.New(), \"placeholder\")\n",
    "batchSize := context.GetParamOr(ctx, \"batch_size\", int(100))\n",
    "logits := LinearModelGraph(ctx, nil, []*Node{Parameter(g, \"images\", shapes.Make(DType, batchSize, mnist.Height, mnist.Width, mnist.Depth))})\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", batchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Loop\n",
    "\n",
    "With a model function defined, we use the training loop create for the MNIST.\n",
    "\n",
    "The trainer is provided in the [`mnist` package](https://github.com/gomlx/gomlx/tree/main/examples/mnist). It is straight forward (and almost the same for every different project) and does the following for us:\n",
    "\n",
    "- If a checkpoing is given (--checkpoint) and it has previously saved model, it loads hyperparmeters and trained variables.\n",
    "- Create trainer: with selected model function (see [Linear model](#Linear-model) and [Linear model for MNIST](#CNN-model-for-MNIST) sections), optimizer, loss and metrics.\n",
    "- Create a `train.Loop` and attach to it a progressbar, a periodic checkpoint saver and a plotter (`--set=\"plots=true\"`).\n",
    "- Train the selected number of train steps.\n",
    "- Report results.\n",
    "\n",
    "Below we train 4000 steps with the default settings just to check things are working."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training linear model:\n",
      "\t- checkpoint in /home/rener/work/mnist/linear\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"dade4a5f\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- restarting from global step 4000\n",
      "\t - target train_steps=4000 already reached. To train further, set a number additional to current global step.\n",
      "\n",
      "Results on train:\n",
      "\tMean Loss+Regularization (#loss+): 0.288\n",
      "\tMean Loss (#loss): 0.288\n",
      "\tMean Accuracy (#acc): 92.04%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.284\n",
      "\tMean Loss (#loss): 0.284\n",
      "\tMean Accuracy (#acc): 92.14%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "var flagCheckpoint = flag.String(\"checkpoint\", \"\", \"Directory save and load checkpoints from. If left empty, no checkpoints are created.\")\n",
    "\n",
    "// trainModel with hyperparameters configured with `-set=...`.\n",
    "func trainModel() {\n",
    "    ctx, paramsSet := ContextFromSettings()\n",
    "    must.M(mnist.TrainModel(ctx, *flagDataDir, *flagCheckpoint, paramsSet))\n",
    "}\n",
    "\n",
    "// Train 50 steps, only to test things are working. No plots.\n",
    "%% --checkpoint=linear  --set=\"model=linear;train_steps=4000;plots=true\"\n",
    "trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model for MNIST\n",
    "\n",
    "Let's now properly define a CNN model to compare.\n",
    "\n",
    "The model was built following a [Deep MNIST for Experts](https://chromium.googlesource.com/external/github.com/tensorflow/tensorflow/+/r0.10/tensorflow/g3doc/tutorials/mnist/pros/index.md)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logits shape for batch_size=10: (Float32)[10 10]\n"
     ]
    }
   ],
   "source": [
    "// CnnModelGraph builds the CNN model for our demo.\n",
    "// It returns the logit, not the predictions, which works with most losses with shape `[batch_size, NumClasses]`.\n",
    "// inputs: only one tensor, with shape `[batch_size, width, height, depth]`.\n",
    "func CnnModelGraph(ctx *context.Context, spec any, inputs []*Node) []*Node {\n",
    "\tctx = ctx.In(\"model\") // Create the model by default under the \"/model\" scope.\n",
    "\tembeddings := CnnEmbeddings(ctx, inputs[0])\n",
    "\tlogits := layers.Dense(ctx, embeddings, true, mnist.NumClasses)\n",
    "\treturn []*Node{logits}\n",
    "}\n",
    "\n",
    "func CnnEmbeddings(ctx *context.Context, images *Node) *Node {\n",
    "\tbatchSize := images.Shape().Dimensions[0]\n",
    "\tg := images.Graph()\n",
    "\tdtype := images.DType()\n",
    "\n",
    "\tlayerIdx := 0\n",
    "\tnextCtx := func(name string) *context.Context {\n",
    "\t\tnewCtx := ctx.Inf(\"%03d_%s\", layerIdx, name)\n",
    "\t\tlayerIdx++\n",
    "\t\treturn newCtx\n",
    "\t}\n",
    "\t// Dropout.\n",
    "\tdropoutRate := context.GetParamOr(ctx, \"cnn_dropout_rate\", -1.0)\n",
    "\tif dropoutRate < 0 {\n",
    "\t\tdropoutRate = context.GetParamOr(ctx, layers.ParamDropoutRate, 0.0)\n",
    "\t}\n",
    "\tvar dropoutNode *Node\n",
    "\tif dropoutRate > 0.0 {\n",
    "\t\tdropoutNode = Scalar(g, dtype, dropoutRate)\n",
    "\t}\n",
    "\n",
    "\timages = layers.Convolution(nextCtx(\"conv\"), images).Filters(32).KernelSize(3).PadSame().Done()\n",
    "\timages.AssertDims(batchSize, 28, 28, 32)\n",
    "\timages = activations.Relu(images)\n",
    "\timages = normalizeCNN(nextCtx(\"norm\"), images)\n",
    "\timages = MaxPool(images).Window(2).Done()\n",
    "\timages.AssertDims(batchSize, 14, 14, 32)\n",
    "\n",
    "\timages = layers.Convolution(nextCtx(\"conv\"), images).Filters(64).KernelSize(3).PadSame().Done()\n",
    "\timages.AssertDims(batchSize, 14, 14, 64)\n",
    "\timages = activations.Relu(images)\n",
    "\timages = normalizeCNN(nextCtx(\"norm\"), images)\n",
    "\timages = MaxPool(images).Window(2).Done()\n",
    "\timages = layers.DropoutNormalize(nextCtx(\"dropout\"), images, dropoutNode, true)\n",
    "\timages.AssertDims(batchSize, 7, 7, 64)\n",
    "\n",
    "\t// Flatten images\n",
    "\timages = Reshape(images, batchSize, -1)\n",
    "\treturn images\n",
    "}\n",
    "\n",
    "func normalizeCNN(ctx *context.Context, logits *Node) *Node {\n",
    "\tnormalizationType := context.GetParamOr(ctx, \"cnn_normalization\", \"none\")\n",
    "\tswitch normalizationType {\n",
    "\tcase \"layer\":\n",
    "\t\tif logits.Rank() == 2 {\n",
    "\t\t\treturn layers.LayerNormalization(ctx, logits, -1).Done()\n",
    "\t\t} else if logits.Rank() == 4 {\n",
    "\t\t\treturn layers.LayerNormalization(ctx, logits, 2, 3).Done()\n",
    "\t\t} else {\n",
    "\t\t\treturn logits\n",
    "\t\t}\n",
    "\tcase \"batch\":\n",
    "\t\treturn batchnorm.New(ctx, logits, -1).Done()\n",
    "\tcase \"none\", \"\":\n",
    "\t\treturn logits\n",
    "\tdefault:\n",
    "\t\texceptions.Panicf(\"invalid normalization type %q -- set it with parameter %q\", normalizationType, \"cnn_normalization\")\n",
    "\t\treturn nil\n",
    "\t}\n",
    "}\n",
    "%% -set=\"batch_size=10\"\n",
    "// Let's test that the logits are coming out with the right shape: we want [batch_size, 10], since there are 10 classes.\n",
    "AssertDownloaded()\n",
    "ctx, _ := ContextFromSettings()\n",
    "g := NewGraph(backends.New(), \"placeholder\")\n",
    "batchSize := context.GetParamOr(ctx, \"batch_size\", int(100))\n",
    "logits := CnnModelGraph(ctx, nil, []*Node{Parameter(g, \"images\", shapes.Make(DType, batchSize, mnist.Height, mnist.Width, mnist.Depth))})\n",
    "fmt.Printf(\"Logits shape for batch_size=%d: %s\\n\", batchSize, logits[0].Shape())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CNN Model Training\n",
    "\n",
    "Let's train the CNN for real this time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "// Remove a previously trained model\n",
    "!rm -rf ~/work/mnist/cnn  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training cnn model:\n",
      "\t- checkpoint in /home/rener/work/mnist/cnn\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div id=\"cf014ec5\"></div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t- restarting from global step 4000\n",
      "\t - target train_steps=4000 already reached. To train further, set a number additional to current global step.\n",
      "\n",
      "Results on train:\n",
      "\tMean Loss+Regularization (#loss+): 0.013\n",
      "\tMean Loss (#loss): 0.013\n",
      "\tMean Accuracy (#acc): 99.59%\n",
      "Results on test:\n",
      "\tMean Loss+Regularization (#loss+): 0.028\n",
      "\tMean Loss (#loss): 0.028\n",
      "\tMean Accuracy (#acc): 99.06%\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%% --checkpoint=cnn --set=\"model=cnn;train_steps=4000;plots=true\"\n",
    "trainModel()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference\n",
    "\n",
    "Inference, or serving the model, is done by using the same code as used to train the model.\n",
    "That is, currently the way to save the model is to export the Go model creation function, along with the checkpoint with learned weights.\n",
    "\n",
    "We created a small library `mnist/classifier` that takes an image as input, convert it to a tensor and calls the trained model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>Image: (28 x 28)</p>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC+0lEQVRIia2VO0szQRSGz+6O5uKCkChWIgYEQUUjCYKlhZZWBiwsbFKIf0FSKKI2/gQhIGrAC4JBUgQEi+C1UAzYC24Es0ajk53ZGYvBEPf2+aGn2j0z85x9z2VW0nXdNE2EEOccfmeSJFFKm5ub0evrq6qqfwjFGEuVSkVVVUmSfkkUxjmvVCoyY4xS+idEAKCUcs5lWZb/ilg3VKvVAoHAP/fpur69vQ0AIlGcc4TQ9PR0S0uLA9Q0TQ+Wpmm5XI5SenBwcHh4aFm9vr5eW1tz4L68vBiGwZ0sm82OjY05BqsnLZVKNR4xDKNcLsuMMbfPLBQK+XxePA8ODo6Ojo6MjAwPD/v9flENAMhkMg7yPZopmUxijD8+Pjo6OqampgKBAGOMMZbP5+fn5zHGiqKMj487nHx6enKT72alUsnv9wNAKBTK5XLO8v+rqwzDWFpawhgDQCwWi0ajDvJ9Ph9jTFGUn+DS6fTR0dHJyYnw9Pf3t7W1OUC9R75UKl1cXMiyXKvV0un03t6e8Le2tiYSiUQi4XzMraVM01xfXx8aGoKvhm+0lZUVx3SLnCKMcTAYtAdjjC0uLj4/PwOAXc3j46OHPknTtFAohBCyQ3d2dnZ3d3t6etrb2ymlwWBQ1/X9/f2rq6ve3t7z83NVVS2nCCHVahV0XfdoKYyxxSPGIRqNvr29ucn3migA8Pl8Fk9nZ6fQ4TE1zlefiGn3X15ezszMAIA9Xd+ghBBLzM3NzXg8XiwWLVtvb28nJycLhQIAmKbZ1NTkBrUGXF1dXVhYIIQcHx9TSt/f3xFClNJsNru1tfXw8AAA8Xg8lUp5QK19OjExIfxdXV19fX2RSCQSiYg8AoCiKLOzs/f3926FFYWyVv/u7m5ubs4eOxwOJ5PJ09NTN9w3qH2iCCEbGxviHxOLxZaXl8/OzorFYrVa9SbWoZKmaeFw2H6h3NzclMvl7u7uuvafmGh+5NYcAwMDP2dZTJZlmRBSf2eM8a9J55w3vgqP22rj0ieuZu0WF49iIgAAAABJRU5ErkJggg=="
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025/02/14 02:29:03 Must not error: requested variable \"weights\" in scope \"/model/model/000_conv/conv\" with Context.Reuse set, but variable does not exist\n",
      "github.com/gomlx/exceptions.Panicf\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/gomlx/exceptions@v0.0.3/exceptions.go:92\n",
      "github.com/gomlx/gomlx/ml/context.(*Context).VariableWithShape\n",
      "\t/home/rener/dev/gomlx/ml/context/context.go:772\n",
      "github.com/gomlx/gomlx/ml/layers.(*ConvBuilder).Done\n",
      "\t/home/rener/dev/gomlx/ml/layers/convolution.go:285\n",
      "github.com/gomlx/gomlx/examples/mnist.CnnEmbeddings\n",
      "\t/home/rener/dev/gomlx/examples/mnist/model.go:72\n",
      "github.com/gomlx/gomlx/examples/mnist.CnnModelGraph\n",
      "\t/home/rener/dev/gomlx/examples/mnist/model.go:46\n",
      "github.com/gomlx/gomlx/examples/mnist/classifier.New.func1\n",
      "\t/home/rener/dev/gomlx/examples/mnist/classifier/classifier.go:66\n",
      "reflect.Value.call\n",
      "\t/usr/local/go/src/reflect/value.go:581\n",
      "reflect.Value.Call\n",
      "\t/usr/local/go/src/reflect/value.go:365\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).buildGraphFn.func1\n",
      "\t/home/rener/dev/gomlx/ml/context/exec.go:312\n",
      "reflect.Value.call\n",
      "\t/usr/local/go/src/reflect/value.go:581\n",
      "reflect.Value.Call\n",
      "\t/usr/local/go/src/reflect/value.go:365\n",
      "github.com/gomlx/gomlx/graph.(*Exec).createAndCacheGraph\n",
      "\t/home/rener/dev/gomlx/graph/exec.go:536\n",
      "github.com/gomlx/gomlx/graph.(*Exec).findOrCreateGraph\n",
      "\t/home/rener/dev/gomlx/graph/exec.go:595\n",
      "github.com/gomlx/gomlx/graph.(*Exec).compileAndExecute\n",
      "\t/home/rener/dev/gomlx/graph/exec.go:436\n",
      "github.com/gomlx/gomlx/graph.(*Exec).CallWithGraph\n",
      "\t/home/rener/dev/gomlx/graph/exec.go:386\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).CallWithGraph\n",
      "\t/home/rener/dev/gomlx/ml/context/exec.go:541\n",
      "github.com/gomlx/gomlx/ml/context.(*Exec).Call\n",
      "\t/home/rener/dev/gomlx/ml/context/exec.go:527\n",
      "github.com/gomlx/gomlx/examples/mnist/classifier.(*Classifier).Classify.func1\n",
      "\t/home/rener/dev/gomlx/examples/mnist/classifier/classifier.go:83\n",
      "github.com/gomlx/exceptions.TryCatch[...]\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/gomlx/exceptions@v0.0.3/exceptions.go:85\n",
      "github.com/gomlx/gomlx/examples/mnist/classifier.(*Classifier).Classify\n",
      "\t/home/rener/dev/gomlx/examples/mnist/classifier/classifier.go:83\n",
      "main.main\n",
      "\t \u001b[7m[[ Cell [21] Line 22 ]]\u001b[0m /tmp/gonb_eb357154/main.go:247\n",
      "runtime.main\n",
      "\t/usr/local/go/src/runtime/proc.go:283\n",
      "runtime.goexit\n",
      "\t/usr/local/go/src/runtime/asm_amd64.s:1700\n",
      "Panicking ...\n",
      "\n",
      "panic: requested variable \"weights\" in scope \"/model/model/000_conv/conv\" with Context.Reuse set, but variable does not exist\n",
      "\n",
      "goroutine 1 [running]:\n",
      "github.com/janpfeifer/must.init.func1({0xeb6a00, 0xc000165050})\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/janpfeifer/must@v0.2.0/must.go:13 +0xd3\n",
      "github.com/janpfeifer/must.M1[...](...)\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/janpfeifer/must@v0.2.0/must.go:41\n",
      "main.main()\n",
      "\t \u001b[7m[[ Cell [21] Line 22 ]]\u001b[0m /tmp/gonb_eb357154/main.go:247 +0x4a2\n",
      "panic: requested variable \"weights\" in scope \"/model/model/000_conv/conv\" with Context.Reuse set, but variable does not exist\n",
      "\n",
      "goroutine 1 [running]:\n",
      "github.com/janpfeifer/must.init.func1({0xeb6a00, 0xc000165050})\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/janpfeifer/must@v0.2.0/must.go:13 +0xd3\n",
      "github.com/janpfeifer/must.M1[...](...)\n",
      "\t/home/rener/.local/go/pkg/mod/github.com/janpfeifer/must@v0.2.0/must.go:41\n",
      "main.main()\n",
      "\t \u001b[7m[[ Cell [21] Line 22 ]]\u001b[0m /tmp/gonb_eb357154/main.go:247 +0x4a2\n",
      "exit status 2\n"
     ]
    }
   ],
   "source": [
    "import (\n",
    "    \"encoding/base64\"\n",
    "    \"image/png\"\n",
    "    \n",
    "    \"github.com/gomlx/gomlx/examples/mnist/classifier\"\n",
    "    // We also must import then engine that will execute the model.\n",
    "    // Currently only XLA is supported.\n",
    "    _ \"github.com/gomlx/gomlx/backends/xla\"\n",
    ")\n",
    "\n",
    "%%\n",
    "// Decode and print PNG image.\n",
    "imgBase64 := bytes.NewBufferString(\"iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAIAAAD9b0jDAAAACXBIWXMAAAsTAAALEwEAmpwYAAAC+0lEQVRIia2VO0szQRSGz+6O5uKCkChWIgYEQUUjCYKlhZZWBiwsbFKIf0FSKKI2/gQhIGrAC4JBUgQEi+C1UAzYC24Es0ajk53ZGYvBEPf2+aGn2j0z85x9z2VW0nXdNE2EEOccfmeSJFFKm5ub0evrq6qqfwjFGEuVSkVVVUmSfkkUxjmvVCoyY4xS+idEAKCUcs5lWZb/ilg3VKvVAoHAP/fpur69vQ0AIlGcc4TQ9PR0S0uLA9Q0TQ+Wpmm5XI5SenBwcHh4aFm9vr5eW1tz4L68vBiGwZ0sm82OjY05BqsnLZVKNR4xDKNcLsuMMbfPLBQK+XxePA8ODo6Ojo6MjAwPD/v9flENAMhkMg7yPZopmUxijD8+Pjo6OqampgKBAGOMMZbP5+fn5zHGiqKMj487nHx6enKT72alUsnv9wNAKBTK5XLO8v+rqwzDWFpawhgDQCwWi0ajDvJ9Ph9jTFGUn+DS6fTR0dHJyYnw9Pf3t7W1OUC9R75UKl1cXMiyXKvV0un03t6e8Le2tiYSiUQi4XzMraVM01xfXx8aGoKvhm+0lZUVx3SLnCKMcTAYtAdjjC0uLj4/PwOAXc3j46OHPknTtFAohBCyQ3d2dnZ3d3t6etrb2ymlwWBQ1/X9/f2rq6ve3t7z83NVVS2nCCHVahV0XfdoKYyxxSPGIRqNvr29ucn3migA8Pl8Fk9nZ6fQ4TE1zlefiGn3X15ezszMAIA9Xd+ghBBLzM3NzXg8XiwWLVtvb28nJycLhQIAmKbZ1NTkBrUGXF1dXVhYIIQcHx9TSt/f3xFClNJsNru1tfXw8AAA8Xg8lUp5QK19OjExIfxdXV19fX2RSCQSiYg8AoCiKLOzs/f3926FFYWyVv/u7m5ubs4eOxwOJ5PJ09NTN9w3qH2iCCEbGxviHxOLxZaXl8/OzorFYrVa9SbWoZKmaeFw2H6h3NzclMvl7u7uuvafmGh+5NYcAwMDP2dZTJZlmRBSf2eM8a9J55w3vgqP22rj0ieuZu0WF49iIgAAAABJRU5ErkJggg==\")\n",
    "imgPNG := must.M1(io.ReadAll(base64.NewDecoder(base64.StdEncoding, imgBase64)))\n",
    "img := must.M1(png.Decode(bytes.NewBuffer(imgPNG)))\n",
    "size := img.Bounds()\n",
    "gonbui.DisplayHTML(fmt.Sprintf(\"<p>Image: (%d x %d)</p>\", size.Dx(), size.Dy()))\n",
    "gonbui.DisplayPNG(imgPNG)\n",
    "\n",
    "// Classify:\n",
    "inference := must.M1(classifier.New(\"~/work/mnist/cnn\"))\n",
    "classID := must.M1(inference.Classify(img))\n",
    "gonbui.DisplayHTML(fmt.Sprintf(\"<p>Class: <b>(%d)</b></p>\", classID))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Go (gonb)",
   "language": "go",
   "name": "gonb"
  },
  "language_info": {
   "codemirror_mode": "",
   "file_extension": ".go",
   "mimetype": "text/x-go",
   "name": "go",
   "nbconvert_exporter": "",
   "pygments_lexer": "",
   "version": "go1.24.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
